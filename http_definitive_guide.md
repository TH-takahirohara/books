HTTP: The Definitive Guide

# Part I: HTTP: The Web's Foundation
- Ch1 ~ Ch4

# Ch1. Overview of HTTP
## 1.1 

## 1.2 Web Clients and Servers
- HTTPサーバーはインターネットのデータを保持し、HTTPクライアントからリクエストされたらそれを渡す。
- 最も一般的なクライアントはWebブラウザ。

## 1.3 Resources
- webサーバーはwebリソースをホストする。webリソースは、webコンテンツの元となるもの。
- 最も単純なwebリソースは、HTMLなどの静的ファイルであるが、静的ファイルでなくても良い。リソースは要求に応じたコンテンツを生成するプログラムでも良い。
- 要約すると、リソースとはあらゆる種類のコンテンツソースのこと。

### 1.3.1 Media Types
- HTTPは、MIMEというデータフォーマットラベルを各オブジェクトに付与して転送する。
- Webサーバは、すべてのHTTPオブジェクトデータにMIMEタイプを付加する。
  - ヘッダー Content-type: image/jpeg のimage/jpegがMIME typeにあたる。
- MIMEタイプは、主なオブジェクトタイプと特定のサブタイプをスラッシュで区切って表現したテキストラベルである。
  - HTMLからなるテキストドキュメントは、text/html となる。

### 1.3.2 URIs
- クライアントは、自分が興味のあるリソースを指摘することができる。サーバーリソース名をURIと呼ぶ。
- URIはインターネットの郵便番号のようなもので、世界中の情報資源を一意に識別し、位置を特定する。
- URIはURLとURNからなる。

### 1.3.3 URLs
- URLは、特定のサーバー上のリソースの特定の場所を示す。
- スキーマ、アドレス、リソースの３箇所に主に分かれる。

### 1.3.4 URNs
- URNは、 リソースが現在どこにあるかに関係なく、特定のコンテンツのユニークな名前を提供する。
- まだ広く採用されていない。対応するインフラが必要なため。

## 1.4 Transactions

### 1.4.1 Methods

### 1.4.2 Status Codes

### 1.4.3 Web pages can consist of multiple objects
- アプリケーションは、タスクを達成するために複数のHTTPトランザクションを発行することがよくある。
- 埋め込まれたリソースは、異なるサーバーに存在することもある。

## 1.5 Messages
- HTTPメッセージはStart line、Header fields、Body からなる。
- ボディには任意のバイナリデータを格納可能

## 1.6 Connection
- TCP
  - エラーのないデータ転送
  - in-order delivery（データは常に送信された順に届く）
  - セグメント化されていないデータストリーム（任意のサイズのデータをいつでも垂れ流すことができる）
- TCP/IPは個々のネットワークやハードウェアの特殊性・欠点を隠す。

## 1.7 Protocol Versions

## 1.8 Architectural components of the web
### 1.8.1 Proxies
- HTTPプロキシサーバーは、Webセキュリティ、アプリケーション統合、パフォーマンス最適化のための重要な構成要素。
- ユーザーの代理として、ユーザーに代わってサーバーにアクセスするアプリケーション。
- プロキシはセキュリティのために使用されることが多く、すべてのウェブトラフィックが流れる信頼できる仲介者として機能する。

### 1.8.2 Caches
- webキャッシュやキャッシングプロキシは、プロキシを通過する主要なドキュメントのコピーを保持する特殊なHTTPプロキシサーバーである。
- クライアントは、離れたwebサーバーからよりも近くのキャッシュを利用することで、はるかに早くドキュメントを取得できる。HTTPは、キャッシュをより効果的にし、キャッシュされたコンテンツの鮮度やプライバシーを管理するための多くの機能を定義している。

### 1.8.3 Gateways
- ゲートウェイとは、他のサーバーを仲介する特別なサーバー。一般にHTTPトラフィックを別のプロトコルに変換する。ゲートウェイはオリジンサーバーのように振る舞うので、クライアントはゲートウェイと通信していると気づかない。

### 1.8.4 Tunnels
- トンネルは、セットアップ後、2つの接続間で生データを盲目的に中継するHTTPアプリケーション。HTTPトンネルは、HTTP以外のデータを1つまたは複数のHTTP接続を介して、データを見ることなく転送するためによく使用される。
- HTTPトンネルは、暗号化されたセキュア・ソケット・レイヤー（SSL）トラフィックをHTTP接続で伝送することで、Webトラフィックのみを許可する企業のファイアウォールを介してSSLトラフィックを許可するという使い方が一般的である。

### 1.8.5 Agents
- ユーザーエージェント（または単にエージェント）は、ユーザーに代わってHTTPリクエストを行うクライアントプログラムである。ブラウザ以外のユーザーエージェントが多くある。
- 例えば、人間が監視することなく、自律的にウェブを歩き回り、HTTPトランザクションを発行したり、コンテンツを取得したりする機械によって自動化されたユーザーエージェントがある。これらの自動化されたエージェントには、「スパイダー」や「ウェブロボット」などのカラフルな名前がついていることが多い。スパイダーは、検索エンジンのデータベースや比較ショッピングロボットの製品カタログなど、ウェブコンテンツの有用なアーカイブを構築するためにウェブを徘徊する。

# Ch2. URLs and Resources
- URLはインターネットリソースの標準的な名前である。

## 2.1 Navigating the Internet's Resources
- URLは、ブラウザが情報を検索する際に必要となるリソースの位置情報です。インターネット上の何十億ものデータリソースを人々やアプリケーションが見つけ、利用し、共有するためのものです。URLは、HTTPやその他のプロトコルに対する人間の通常のアクセスポイントです。人間がブラウザでURLを指定すると、裏ではブラウザが適切なプロトコルメッセージを送信し、人間が求めるリソースを取得します。
- URLの最初の部分はURLスキーマ。webクライアントに「どうやって」リソースにアクセスするかを伝える。
- URLの第二の部分はサーバーの場所。webクライアントに、リソースが「どこに」ホストされているかを伝える。
- URLの第三の部分は、リソースパス。これはサーバー上の「何の」ローカルリソースがリクエストされているかを伝える。
- 世の中にあるすべてのリソースと、そのリソースを得るためのすべての方法に対して、それぞれのリソースに単一の名前を付けることで、誰もがその名前を使ってリソースを見つけることができるようになっているのです。しかし、これは必ずしもそうではありませんでした。

### 2.1.1 The dark days before URLs

## 2.2 URL Syntax
- ほとんどのURLは一般的なURL構文に準拠しており、異なるURLスキームの間でスタイルや構文が大きく重複しています。
- ほとんどのURLは9つのパートに分かれる。

```
<scheme>://<user>:<password>@<host>:<port>/<path>;<params>?<qu
ery>#<frag>
```
- これらの構成要素をすべて含むURLはほとんどありません。最も重要な要素はscheme, host, pathです。

### 2.2.1 Schemes: What Protocol to Use
- schemeは与えられたリソースにアクセスする方法についての主要なIDである。schemeはURLを解釈するアプリケーションに、どのプロトコルを使う必要があるかを伝える。

### 2.2.2 hosts and ports
- インターネット上のリソースを見つけるために、アプリケーションはリソースをホストしているマシンを知り、そのマシンのどこに目的のリソースにアクセスできるサーバーがあるのかを知る必要があります。
- hostコンポーネントは、リソースにアクセスできるインターネット上のホストマシンを特定します。名前は、上記のようにホスト名（「www.joes-hardware.com」）として提供することも、IPアドレスとして提供することもできます。
- portコンポーネントは、サーバーがリッスンしているネットワークポートを特定します。基本的にTCPプロトコルを使用するHTTPの場合、デフォルトのポートは80です。

### 2.2.3 usernames and passwords

### 2.2.4 Paths
- URLのpathコンポーネントは、サーバーマシン上のどこにリソースがあるかを指定します。

### 2.2.5 parameters
- アプリケーションがサーバーと正しく対話するために必要な入力パラメータを与えるために、URLにはparamsコンポーネントがあります。このコンポーネントは、URL内の名前と値のペアのリストで、URLの他の部分と（そしてお互いに）「;」文字で区切られています。このコンポーネントは、アプリケーションがリソースにアクセスするために必要な追加情報を提供します。

### 2.2.6 query strings
- データベースサービスなどの一部のリソースでは、要求されているリソースの種類を絞り込むために、質問や問い合わせをすることができます。
- URLのqueryコンポーネントはゲートウェイ・リソースに渡され、URLのpathコンポーネントはゲートウェイ・リソースを特定します。基本的に、ゲートウェイは他のアプリケーションへのアクセスポイントと考えることができます。

### 2.2.7 fragments
- リソースの一部や断片を参照できるように、URLはリソース内の断片を識別するfragコンポーネントをサポートしています。例えば、URLは、HTMLドキュメント内の特定の画像やセクションを指し示すことができます。
- フラグメントは、URLの右端に#文字を付けてぶら下げます。
- クライアントはリソース全体を取得した後、fragmentで指定するリソースの部分を表示する。（ブラウザの場合、そこまでスクロールする。）

## 2.3 URL Shortcuts
- Web クライアントは、いくつかの URL ショートカットを理解して使用しています。相対URLは、リソースの中にリソースを指定する便利な略語です。また、多くのブラウザはURLの「自動展開」をサポートしています。ユーザーがURLの重要な（記憶に残る）部分を入力すると、ブラウザが残りの部分を埋めてくれます。

### 2.3.1 Relative URLs - 相対URL
- URLには、絶対URLと相対URLの2種類があります。
- ここまでは、絶対URLについてのみ説明してきました。絶対URLには、リソースにアクセスするために必要な情報がすべて含まれています。一方、相対URLは不完全なものです。相対URLからリソースへのアクセスに必要なすべての情報を得るためには、ベースと呼ばれる別のURLから相対的に解釈しなければなりません。相対URLは、URLの便利な略記法です。
- 省略可能な相対URL構文により、HTML作成者はURLからスキームやホストなどの構成要素を省略することができます。これらの要素は、それらが含まれるリソースのベースURLから推測できます。他のリソースのURLもこの短縮形で指定することができます。
- また、相対URLは、一連のリソース（HTMLページなど）をポータブルに保つための便利な方法です。相対URLを使用すると、一連のドキュメントを移動しても、新しいベースに対して相対的に解釈されるため、リンクが機能します。これにより、他のサーバにコンテンツをミラーリングすることなどが可能になります。

#### 2.3.1.1 Base URLs
- 変換プロセスの最初のステップは、ベースURLを見つけることです。ベースURLは、相対URLを参照するためのポイントとなります。ベースURLはいくつかの場所から得られます。
  - リソースで明示されている
  - カプセル化されたリソースのベースURL　（HTMLなど）相対URLが埋め込まれているリソースのURLをベースにすることができる。
  - ベースとなるURLがない

#### 2.3.1.2 Resolving relative references
- 相対URLを絶対URLに変換するアルゴリズムがある。もともとRFC1808で規定され、その後RFC2396に組み込まれた。

### 2.3.2 Expandomatic URLs - URLの拡大
- 一部のブラウザでは、URLを送信した後や入力中に、自動的にURLを展開しようとするものがあります。これにより、ユーザーは完全なURLを入力する必要がなく、自動的に展開されるため、ショートカットを得ることができます。
- これらの「expandomatic」機能には、2つの種類があります。
  - ホスト名展開
    - ブラウザは簡単なヒューリスティクスを利用して、ユーザーの助けを借りずに、入力したホスト名を完全なホスト名に展開することができます。
  - 履歴の展開
    - URLを入力する手間を省くためにブラウザが採用しているもうひとつのテクニックが、過去にアクセスしたURLの履歴を保存することです。URLを入力する際に、入力した内容と履歴に残っているURLの接頭辞を照合することで、完成度の高い選択肢を提供することができます。

## 2.4 Shady Characters
- URLには、比較的小さく、普遍的に安全なアルファベットの文字のみを含めることが許可されている。
- URLは完全でなければなりません。URL の設計者は、URL にバイナリデータや、普遍的に安全なアルファベット以外の文字を含めたいと思う場合があることに気付きました。そこで、安全でない文字を安全な文字にエンコードして転送できるように、エスケープメカニズムを追加しました。

### 2.4.1 The URL Character Set
- URL設計者は、完全性の必要性を認識して、エスケープシーケンスを取り入れました。エスケープシーケンスは、任意の文字値やデータをUS-ASCII文字セットの限定されたサブセットを使ってエンコードすることで、移植性と完全性を実現します。

### 2.4.2 Encoding Mechanisms
- 安全な文字セットの表現の限界を回避するために、安全ではないURLの文字を表現するエンコード方式が考案されました。このエンコーディングでは、安全でない文字を、パーセント記号（%）と、その文字のASCIIコードを表す2つの16進数からなる「エスケープ」表記で単純に表します。

### 2.4.3 Character Restrictions - 文字の制限
- いくつかの文字は、URLの中で特別な意味を持つように予約されています。

### 2.4.4 A Bit More

## 2.5 A sea of schemes
- httpスキーマは、usernameとpasswordがないこと以外は一般的なURLフォーマットと同じ。デフォルトポートは80。
- https
- mailto

## 2.6 the future
- URN
- PURL

# Ch3 HTTP Messages
- HTTP がインターネットの運び屋であるとすれば、HTTP メッセージは物を移動するためのパッケージです。この章では以下を学びます。
  - メッセージの流れ
  - HTTP メッセージの 3 つの部分 (開始行、ヘッダー、エンティティボディ)
  - リクエストメッセージとレスポンスメッセージの違い
  - リクエストメッセージがサポートするさまざまな機能（メソッド）について
  - レスポンスメッセージで返されるさまざまなステータスコード
  - 各種 HTTP ヘッダーの役割 

## 3.1 The Flow of Messages
- HTTPメッセージは、HTTPアプリケーション間で送信されるデータのブロックです。これらのデータブロックは、メッセージの内容や意味を説明するテキストのメタ情報で始まり、その後にオプションのデータが続きます。これらのメッセージは、クライアント、サーバー、およびプロキシの間を流れます。メッセージの方向性を示す用語として、「インバウンド」、「アウトバウンド」、「アップストリーム」、「ダウンストリーム」があります。

### 3.1.1 Messages Commute Inbound to the Origin Server
- HTTPでは、トランザクションの方向性を表すために、インバウンドとアウトバウンドという用語を使用しています。メッセージはオリジンサーバーに向かってインバウンドで送信され、その作業が終わるとユーザーエージェントに向かってアウトバウンドで送信されます（図3-1参照）。

### 3.1.2 Messages Flow Downstream
- HTTP メッセージは川のように流れます。すべてのメッセージは、リクエスト・メッセージかレスポンス・メッセージかにかかわらず、下流に向かって流れます（図3-2参照）。メッセージの送信者は受信者の上流に位置します。

## 3.2 The Parts of a Message
- HTTPメッセージは、フォーマットされたシンプルなデータの塊です。図3-3にその例を示していますのでご覧ください。各メッセージには、クライアントからのリクエストまたはサーバからのレスポンスが含まれています。メッセージは3つの部分から構成されています。メッセージを説明するスタートライン、属性を含むヘッダーのブロック、そしてデータを含むオプションのボディです。
- 開始行とヘッダーは単なるASCIIテキストで、行ごとに区切られています。各行の終わりには、キャリッジリターン（ASCII 13）とラインフィード（ASCII 10）の2文字の行末シーケンスがあります。
- この行末記号は "CRLF "と表記されます。HTTPの行末仕様はCRLFですが、堅牢なアプリケーションでは、ラインフィード文字だけを受け入れるべきであることを指摘しておきます。古いHTTPアプリケーションや壊れたHTTPアプリケーションの中には、キャリッジリターンとラインフィードの両方を送るとは限らないものもあります。
- エンティティボディまたはメッセージボディ（または単に「ボディ」）は、単なるオプションのデータチャンクです。開始行やヘッダーとは異なり、ボディにはテキストやバイナリデータを含めることができ、また空にすることもできます。

### 3.2.1 Message Syntax
- すべてのHTTPメッセージは、「リクエストメッセージ」と「レスポンスメッセージ」の2種類に分類されます。リクエストメッセージはウェブサーバに動作を要求し，レスポンスメッセージはリクエストの結果をクライアントに返します。
```
// リクエストメッセージのフォーマット
<method> <request-URL> <version>
<headers>

<entity-body> 

// レスポンスメッセージのフォーマット
<version> <status> <reason-phrase>
<headers>

<entity-body>
```
- method
  - クライアントがサーバーにリソースに対して実行してほしいアクション。GET"、"HEAD"、"POST "などの単一の単語で構成されます。この章の後半では、メソッドについて詳しく説明します。
- request-URL
  - 要求されたリソースを指定する完全なURL、またはURLのパスコンポーネントです。サーバーと直接やりとりする場合は、リソースへの絶対パスであれば、通常、URLのパスコンポーネントは問題ありません（サーバーは自分自身をURLのホスト／ポートとみなすことができます）。
- version
- status-code
- reason-phrase
  - ステータスコードの数値を人間が読めるようにしたもので、行末までのすべてのテキストで構成される。理由のフレーズは、人間が消費するためだけのものです。
- headers
  - 0個以上のヘッダは、名前の後にコロン(:)、任意のホワイトスペース、値、CRLFが続きます。ヘッダーは空行 (CRLF) で終了し、ヘッダーのリストの終わりと、エンティティボディの始まりを示します。HTTP/1.1 などの一部のバージョンの HTTP では、リクエストやレスポンスのメッセージが有効であるために、特定のヘッダが存在することが要求されます。様々な HTTP ヘッダーについては、この章の後半で説明します。
- entity-body
  - エンティティボディは、任意のデータブロックを含みます。すべてのメッセージにエンティティ・ボディが含まれているわけではないので、メッセージが CRLF で終了することもあります。エンティティについては第 15 章で詳しく説明します。
- HTTP ヘッダは、ヘッダがなくても、エンティティボディがなくても、常に空行(CRLF)で終わるべきであることに注意してください。しかし、これまで多くのクライアントやサーバーは、エンティティボディがない場合、最後のCRLFを（誤って）省略していました。

### 3.2.2 Start Lines

#### 3.2.2.1 リクエスト・ライン
- リクエスト・メッセージは、リソースに対して何かをするようサーバに要求します。リクエスト・メッセージのスタート・ライン（リクエスト・ライン）には、サーバが実行すべき操作を記述したメソッドと、そのメソッドを実行するリソースを記述したリクエストURLが含まれます。また、リクエストラインには、クライアントが使用しているHTTPの方言をサーバーに伝えるHTTPバージョンも含まれています。
- これらのフィールドはすべてホワイトスペースで区切られています。

#### 3.2.2.2 レスポンスライン
- レスポンス・メッセージは、操作によって得られたステータス情報や結果のデータをクライアントに返します。レスポンスメッセージの開始行（レスポンスライン）には、レスポンスメッセージが使用しているHTTPバージョン、数値化されたステータスコード、操作のステータスを説明するテキストの理由フレーズが含まれます。これらのフィールドはすべて、ホワイトスペースで区切られています。

#### 3.2.2.2 メソッド
- メソッドは、リクエストの開始行を開始し、サーバーに何をすべきかを伝えます。たとえば、「GET /specials/saw-blade.gif HTTP/1.0」という行では、メソッドはGETです。
- HTTPの仕様では、一般的なリクエストメソッドのセットが定義されています。例えば、GETメソッドはサーバーからドキュメントを取得し、POSTメソッドはサーバーにデータを送信して処理を行い、OPTIONSメソッドはWebサーバーの一般的な機能や特定のリソースに対するWebサーバーの機能を決定します。
- 表3-1では、これらのうち7つのメソッドについて説明しています。なお、リクエストメッセージにボディがあるメソッドと、ボディのないリクエストがあるメソッドがあります。
- すべてのサーバーが表3-1の7つのメソッドをすべて実装しているわけではありません。また、HTTPは拡張性を重視して設計されているため、他のサーバーがこれらに加えて独自のリクエストメソッドを実装している場合もあります。これらの追加メソッドは、HTTPの仕様を拡張するものであるため、拡張メソッドと呼ばれます。

#### 3.2.2.4 ステータスコード
- ステータスコードは、各応答メッセージの開始行に返されます。ステータスには、数字と人間が読める文字の両方が含まれます。数字はプログラムのエラー処理を容易にし、理由は人間が理解しやすいようになっています。
- それぞれのステータスコードは、3桁の数値コードによってクラス分けされています。200から299までのステータスコードは成功を表す。300から399までのコードは、リソースが移動されたことを示す。400から499までのコードは、クライアントがリクエストで何か間違ったことをしたことを意味します。500から599までのコードは、サーバー上で何か問題が発生したことを意味します。
- 現在のバージョンのHTTPでは、各ステータスカテゴリにいくつかのコードしか定義されていません。プロトコルの進化に伴い、より多くのステータスコードがHTTP仕様で公式に定義される予定です。見覚えのないステータスコードを受け取った場合は、誰かが現在のプロトコルの拡張として定義した可能性があります。そのコードは、そのコードが含まれるクラスの一般的なメンバーとして扱われるべきです。

#### 3.2.2.5 reason phrases
- HTTPの仕様では、理由を示す語句がどのようなものであるべきか、明確なルールは定められていません。

#### 3.2.2.6 Version numbers
- バージョン番号は、HTTP アプリケーションが相互にどのバージョンのプロトコルに準拠しているかを伝える手段となります。バージョン番号は、HTTP を使用するアプリケーションに、互いの能力やメッセージの形式についての手がかりを提供することを目的としています。HTTP バージョン 1.1 のアプリケーションと通信する HTTP バージョン 1.2 のアプリケーションは、1.2 の新機能を使用すべきではないことを知るべきです。なぜなら、それらの機能は、古いバージョンのプロトコルを使用するアプリケーションによって実装されていない可能性が高いからです。

### 3.2.3 Headers
- HTTP ヘッダーフィールドは、リクエストとレスポンスのメッセージに追加の情報を与えます。これらは基本的に、名前と値のペアのリストです。

#### 3.2.3.1 Header classifications
- 各HTTPヘッダーは、名前の後にコロン（：）、任意のホワイトスペース、フィールド値、CRLFというシンプルな構文になっています。

### 3.2.4 Entity Bodies
- HTTPメッセージの第3の部分は、オプションのエンティティボディです。エンティティボディは、HTTPメッセージのペイロードです。エンティティボディは、HTTPメッセージのペイロードであり、HTTPが輸送するために設計されたものです。
- HTTPメッセージは、画像、ビデオ、HTML文書、ソフトウェアアプリケーション、クレジットカード、電子メールなど、さまざまな種類のデジタルデータを伝送することができます。

### 3.2.5 Version 0.9 Messages

## 3.3 Methods
- ここでは、表3-1に示した基本的なHTTPメソッドのいくつかについて詳しく説明します。ただし、すべてのサーバがすべてのメソッドを実装しているわけではありません。HTTP バージョン 1.1 に準拠するためには、サーバーはそのリソースに対して GET と HEAD メソッドのみを実装する必要があります。
- サーバーがこれらのメソッドをすべて実装していたとしても、そのメソッドはほとんどの場合、用途が制限されています。例えば、DELETEやPUT（後述）をサポートするサーバは、誰でもリソースを削除したり保存したりできることを望んでいません。このような制限は、一般的にはサーバーの設定で設定されるため、サイトやサーバーによって異なります。

### 3.3.1 Safe Methods
- HTTP では、安全なメソッドと呼ばれる一連のメソッドが定義されています。GET メソッドと HEAD メソッドは安全であると言われています。つまり、GET メソッドまたは HEAD メソッドを使用した HTTP リクエストの結果、何も起こらないことを意味します。何も起こらないというのは、HTTPリクエストの結果としてサーバー上で何も起こらないということです。
- 例えば、あなたがJoe's Hardwareでオンラインショッピングをしていて、「購入」ボタンをクリックしたとします。このボタンをクリックすると、クレジットカード情報を含むPOSTリクエスト(後述)が送信され、お客様に代わってサーバー上でアクションが実行されます。この場合のアクションとは、お客様のクレジットカードに購入代金が請求されることです。
- 安全なメソッドを使用しても、アクションが実行されないという保証はありません（実際には、ウェブ開発者次第ですが...）。安全なメソッドとは、何らかのアクションが実行される可能性のある安全でないメソッドが使用されている場合に、HTTPアプリケーションの開発者がユーザーに知らせるためのものです。Joe's Hardwareの例では、Webブラウザが警告メッセージを表示し、安全でないメソッドでリクエストを行っていること、その結果、サーバ上で何かが起こる可能性があることを知らせます（例：クレジットカードに課金される）。

### 3.3.2 GET
- GETは最も一般的なメソッドです。通常、サーバーにリソースの送信を依頼する際に使用されます。HTTP/1.1では、サーバーがこのメソッドを実装する必要があります。

### 3.3.3 HEAD
- ヘッダーだけを返すメソッド。下記用途で使う。
  - リソースを取得せずに、そのリソースについて調べる（例えば、タイプを決定する）。
  - レスポンスのステータスコードを見て、オブジェクトが存在するかどうかを確認する。
  - ヘッダを見て、リソースが変更されたかどうかを確認する。

- サーバの開発者は、返されるヘッダが、GETリクエストが返すヘッダと同じであることを確認する必要があります。HTTP/1.1 に準拠するためには、HEAD メソッドも必要です。

### 3.3.4 PUT
- PUTメソッドは、GETがサーバーからドキュメントを読み取るのとは逆に、サーバーにドキュメントを書き込むものである。パブリッシングシステムの中には、PUTを使ってWebページを作成し、Webサーバーに直接インストールできるものもある（図3-9参照）。
- PUTメソッドのセマンティクスは、サーバーがリクエストのボディを受け取り、それを使ってリクエストされたURLで名付けられた新しいドキュメントを作成するか、そのURLがすでに存在する場合は、ボディを使ってそれを置き換えるというものです。PUTはコンテンツの変更を可能にするため、多くのウェブサーバーではPUTを実行する前にパスワードによるログインを要求しています。パスワード認証については、第12章で詳しく説明しています。

### 3.3.5 POST
- OSTメソッドは、入力データをサーバーに送信するために設計されました *。 実際には、HTMLフォームをサポートするためによく使用されます。入力されたフォームからのデータは通常、サーバーに送信され、サーバーはそれを必要な場所（例えば、サーバー・ゲートウェイ・プログラムに送信し、それを処理します）に転送します。
- * POSTは、データをサーバーに送信するために使用されます。PUTは、サーバー上のリソース（ファイルなど）にデータを預けるために使用されます。

### 3.3.6 TRACE
- クライアントがリクエストを行う際、そのリクエストは、ファイアウォール、プロキシ、ゲートウェイ、その他のアプリケーションを経由しなければならない場合があります。これらのそれぞれが、オリジナルのHTTPリクエストを変更する機会を持っています。TRACEメソッドでは、クライアントは、リクエストが最終的にサーバに到達したときの様子を確認することができます。
- TRACEリクエストは、送信先のサーバで「ループバック」診断を開始します。最終目的地のサーバは、受け取ったバージンリクエストメッセージを本文に含んだTRACEレスポンスを返信します。クライアントは、元のメッセージが、HTTPアプリケーションのリクエスト／レスポンスチェーンに沿って、どのように、あるいはどのように変更されたかを確認することができます（図3-11参照）。
- TRACEメソッドは、主に診断のために使用されます。つまり、リクエストが意図したとおりにリクエスト／レスポンスチェーンを通過しているかどうかを検証します。また、プロキシや他のアプリケーションがリクエストに与える影響を確認するのにも適したツールです。TRACEは診断に適していますが、介在するアプリケーションが異なるタイプのリクエスト（異なるメソッド-GET、HEAD、POSTなど）を同じように扱うことを前提としているという欠点があります。多くの HTTP アプリケーションは、メソッドに応じて異なる処理を行います。一般的に、TRACEリクエストをどのように処理するかについては、介在するアプリケーションが判断します。
- TRACEリクエストでは、エンティティボディを送信することはできません。TRACEレスポンスのエンティティボディには、応答サーバが受け取ったリクエストがそのまま含まれています。

### 3.3.7 OPTIONS
- OPTIONSメソッドは、ウェブサーバがサポートしている様々な機能について、サーバに問い合わせるものです。一般的に、あるいは特定のリソースに対してどのようなメソッドをサポートしているかをサーバーに尋ねることができます。(サーバーによっては、特定の種類のオブジェクトに対してのみ特定の操作をサポートしている場合もあります)。
- これにより、クライアントアプリケーションは、様々なリソースに実際にアクセスすることなく、どのようにアクセスするのが最適かを判断することができます。

### 3.3.8 DELETE
- DELETEメソッドは、イメージ通り、リクエストURLで指定されたリソースの削除をサーバーに依頼するものです。しかし、クライアントアプリケーションは、その削除が実行されることを保証されていません。これは、HTTPの仕様では、サーバーがクライアントに断りなくリクエストを上書きすることができるためです。

### 3.3.9 Extension Methods
- HTTPは、新しい機能が旧来のソフトウェアの障害とならないように、フィールド拡張可能な設計となっています。
- 注意すべき点は、すべての拡張メソッドが正式な仕様で定義されているわけではないということです。拡張メソッドを定義しても、ほとんどの HTTP アプリケーションでは理解できない可能性があります。同様に、他のアプリケーションが使用している、理解できない拡張メソッドにHTTPアプリケーションが遭遇する可能性もあります。
- このような場合には、拡張メソッドに対して寛容であることが最善です。プロキシは、エンドツーエンドの動作を壊すことなく、未知のメソッドを持つメッセージを下流のサーバに中継することが可能であれば、それを試みるべきです。そうでない場合は、501 Not Implementedのステータスコードで応答すべきです。

## 3.4 Status Codes
- HTTPステータスコードは、前述の表3-2に示すように、大きく5つのクラスに分類されます。ここでは、5つのクラスごとにHTTPステータスコードをまとめています。

### 3.4.1 100-199: Informational Status Codes

### 3.4.2 200-299: Success Status Codes

### 3.4.3 300-399: Redirection Status Codes
- リダイレクションのステータスコードは、クライアントが興味を持っているリソー スのために別の場所を使用するように伝えるか、あるいはコンテンツの代わりに別の 応答を提供する。リソースが移動した場合には、リダイレクト・ステータス・コードとオプションのLocationヘッダを送信して、リソースが移動したことと、現在どこで見つけられるかをクライアントに伝えることができます（図3-14参照）。これにより、ブラウザは人間のユーザに迷惑をかけることなく、透過的に新しい場所に移動することができます。
- リダイレクトステータスコードの中には、アプリケーションのリソースのローカルコピーをオリジンサーバーで検証するために使用できるものがあります。例えば、HTTPアプリケーションは、リソースのローカルコピーがまだ最新であるかどうか、またはリソースがオリジンサーバーで変更されているかどうかを確認することができます。確認して変更がない旨のレスポンス（304 Not Modified）が返ってきたら、ローカルコピー（キャッシュなど）を表示する。
- 304
  - クライアントは、リクエストヘッダーを含めることで、リクエストを条件付きで行うことができます。条件付きヘッダの詳細については、第3章を参照してください。クライアントが、リソースが最近変更されていない場合のGETなど、条件付きのリクエストを行う場合、リソースが変更されていないことを示すためにこのコードが使用されます。

### 3.4.4 400-499: Client Error Status Codes

### 3.4.5 500-599: Server Error Status Codes

## 3.5 Headers
- ヘッダーとメソッドが連携して、クライアントとサーバーの動作を決定します。このセクションでは、標準的な HTTP ヘッダーと、HTTP/1.1 仕様 (RFC 2616) で明示的に定義されていないいくつかのヘッダーの目的について、簡単に説明します。付録Cでは、これらすべてのヘッダーの詳細をまとめています。
- ヘッダーには、メッセージの種類ごとに固有のものと、リクエストメッセージとレスポンスメッセージの両方に情報を提供する、より一般的な目的のものとがあります。ヘッダーには、大きく分けて5つのクラスがあります。
  - General headers
  - Request headers
  - Response headers
  - Entity headers
    - エンティティ・ヘッダとは、エンティティ・ボディを扱うヘッダのことです。例えば、エンティティヘッダは、エンティティボディ内のデータのタイプを伝えることができます。
  - Extension headers

### 3.5.1 General Headers

### 3.5.2 Request Headers

### 3.5.3 Response Headers

### 3.5.4 Entity Headers
- HTTP メッセージのペイロードを記述するヘッダは数多くあります。リクエストメッセージにもレスポンスメッセージにもエンティティが含まれるため、これらのヘッダはどちらのタイプのメッセージにも含まれます。エンティティヘッダーは、オブジェクトのタイプに関する情報から、リソース上で実行可能な有効なリクエストメソッドまで、エンティティとそのコンテンツに関する幅広い情報を提供します。一般的に、エンティティヘッダーは、メッセージの受信者に何を扱っているかを伝えます。表3-21は、エンティティ情報ヘッダーの一覧です。

#### 3.5.4.1 Content headers
- コンテンツヘッダーは、エンティティのコンテンツに関する特定の情報を提供し、そのタイプ、サイズ、その他処理に役立つ情報を明らかにします。例えば、Webブラウザは返されたコンテンツタイプを見て、オブジェクトをどのように表示するかを知ることができます。表3-22は、さまざまなコンテンツヘッダーの一覧です。

#### 3.5.4.2 Entity caching headers
- 一般的なキャッシュヘッダは、いつ、どのようにキャッシュするかを指示します。エンティティキャッシュヘッダは、キャッシュされるエンティティに関する情報を提供します。たとえば、リソースのキャッシュされたコピーがまだ有効であるかどうかを検証するために必要な情報や、キャッシュされたリソースがいつ無効になるかをよりよく見積もるためのヒントを提供します。
- 第7章では、HTTPリクエストとレスポンスのキャッシュについて詳しく説明します。これらのヘッダは、そこで再び目にすることになるでしょう。表3-23は、エンティティキャッシュヘッダーの一覧です。

# Ch4 Connection Management
- HTTP仕様では、HTTPメッセージについてはよく説明されていますが、HTTPメッセージが流れる際の重要な配管であるHTTPコネクションについてはあまり説明されていません。もしあなたがHTTPアプリケーションを書いているプログラマーならば、HTTPコネクションの裏と表、そしてその使い方を理解する必要があります。
- HTTP 接続の管理は、ちょっとしたブラックアートのようなもので、出版された文献からだけでなく、実験や見習いからも学ぶことができます。この章では、以下のことを学びます。
  - HTTPのTCPコネクションの使い方
  - TCP 接続の遅延、ボトルネック、詰まり
  - HTTP の最適化 (並列接続、キープアライブ接続、パイプライン接続など)
  - 接続を管理する上での注意点 

## 4.1 TCP Connections
- 世界中のHTTP通信は、世界中のコンピュータやネットワーク機器で使用されているパケットスイッチネットワークプロトコルであるTCP/IPを介して行われています。クライアントアプリケーションは、世界中のあらゆる場所で動作しているサーバーアプリケーションとのTCP/IP接続を開くことができます。いったん接続が確立されると、クライアントとサーバーのコンピュータ間で交換されたメッセージが失われたり、破損したり、順番が狂って受信されることはありません。

### 4.1.1 TCP Reliable Data Pipes
- HTTP接続の正体は、TCP接続と、その使い方に関するいくつかのルールに過ぎません。TCP接続は、インターネットの信頼できる接続です。データを正確かつ迅速に送信するためには、TCPの基本的な知識が必要です。
- TCP は HTTP に信頼性の高いビットパイプを提供します。TCPコネクションの片側に詰め込まれたバイトは、正しい順序で反対側に出てきます（図4-2参照）。

### 4.1.2 TCP Streams Are Segmented and Shipped by IP Packets - TCPストリームを分割してIPパケットで出荷する
- TCPは、IPパケット（またはIPデータグラム）と呼ばれる小さな塊でデータを送信します。このように、HTTP は「HTTP over TCP over IP」という「プロトコル・スタック」の最上位の層です（図 4-3a）。安全なバージョンであるHTTPSは、HTTPとTCPの間に暗号化層（TLSまたはSSLと呼ばれる）を挿入します（図4-3b）。
- HTTP は、メッセージを送信する際に、開いている TCP コネクションを介して、メッセージデータのコンテンツを順にストリームします。TCP は、データのストリームを受け取り、セグメントと呼ばれる塊に切り分け、IP パケットと呼ばれるエンベロープ内でセグメントをインターネット上に転送します (図 4-4 参照)。これらはすべてTCP/IPソフトウェアによって処理され、HTTPプログラマーには何も見えません。
各TCPセグメントは、IPパケットによって、あるIPアドレスから別のIPアドレスへと運ばれます。これらのIPパケットには、以下のものが含まれます。

  - IPパケットヘッダ（通常20バイト
  - TCPセグメントのヘッダ（通常20バイト
  - TCPデータのチャンク（0バイトまたはそれ以上

- IPヘッダには、送信元と送信先のIPアドレス、サイズ、その他のフラグが含まれています。TCPセグメントヘッダには、TCPポート番号、TCP制御フラグ、データの順序付けや整合性チェックに使用する数値などが含まれます。

### 4.1.3 Keeping TCP Connections Straight
- コンピュータは、一度に複数のTCPコネクションを開いていることがあります。TCPは、これらの接続をポート番号で管理しています。ポート番号は、社員の電話の内線番号のようなものです。会社の電話番号がフロントデスクにつながり、内線番号が適切な従業員につながるように、IPアドレスが適切なコンピュータにつながり、ポート番号が適切なアプリケーションにつながるのです。TCP接続は4つの値で区別されます。

```
<source-IP-address, source-port, destination-IP-address,
destination-port>
```

- これらの4つの値を組み合わせることで、接続を一意に定義します。2つの異なるTCPコネクションは、4つのアドレス構成要素すべてに同じ値を持つことはできません（ただし、異なるコネクションが、いくつかの構成要素に同じ値を持つことは可能です）。図4-5では、4つのコネクションがあります。各ポートの関連情報を表4-1に示します。

### 4.1.4 Programming with TCP Sockets
- オペレーティングシステムは、TCP接続を操作するためのさまざまな機能を提供しています。
- ソケットAPIは、TCPとIPの詳細をすべてHTTPプログラマから隠しています。
- ソケット API では、TCP エンドポイントのデータ構造を作成したり、これらのエンドポイントをリモート・サーバの TCP エンドポイントに接続したり、データ・ストリームを読み書きしたりすることができます。TCP APIでは、基礎となるネットワーク・プロトコルのハンドシェイクや、IPパケットとの間で行われるTCPデータ・ストリームのセグメント化と再構成などの詳細はすべて隠されています。

### 4.2 TCP Performance Considerations
- HTTP は TCP に直接レイヤリングされているため、HTTP トランザクションのパフォーマンスは、基礎となる TCP 配管のパフォーマンスに決定的に依存します。このセクションでは、これらのTCP接続のパフォーマンスに関するいくつかの重要な検討事項を紹介します。TCP の基本的なパフォーマンス特性を理解することで、HTTP の接続最適化機能をよりよく理解することができ、よりパフォーマンスの高い HTTP アプリケーションを設計、実装することができます。

### 4.2.1 HTTP Transaction Delays
- 基本的に、ほとんどのHTTPの遅延はTCPネットワークの遅延が原因である。
  - DNSルックアップ　ローカルにキャッシュされていない場合、数十秒かかることもある。
  - TCPコネクション確立　新しいTCP接続ごとに発生する。通常はせいぜい1,2秒だが、HTTPトランザクションが多数発生すると累積する。
  - TCP接続確立後のリクエスト、レスポンスがインターネット上を移動し、処理されるまでの時間がかかる。

### 4.2.2 Performance Focus Areas
- このセクションでは、HTTPプログラマに影響を与える最も一般的なTCP関連の遅延について、その原因やパフォーマンスへの影響などを説明します。

  - TCP 接続設定のハンドシェイク
  - TCP スロースタート輻輳制御
  - データ集約のためのNagleのアルゴリズム
  - TCPの遅延確認応答アルゴリズムによるピギーバック確認応答
  - TIME_WAITの遅延とポートの枯渇

### 4.2.3 TCP Connection Handshake Delays

### 4.2.4 Delayed Acknowledgments

### 4.2.5 TCP Slow Start

### 4.2.6 Nagle's Algorithm and TCP_NODELAY

### 4.2.7 TIME_WAIT Accumulation and Port Exhaustion

## 4.3 HTTP Connection Handling
- この章の残りの部分では、接続を操作して最適化するための HTTP 技術について説明します。まず、誤解されがちですが、HTTP接続管理の重要な部分であるHTTP Connectionヘッダーについて説明します。次に、HTTP の接続最適化技術について説明します。

### 4.3.1 The Oft-Misunderstood Connection Header - 意外と知られていない接続用ヘッダー
- HTTPでは、クライアントと最終的なオリジンサーバーの間に、一連のHTTP中間体が存在します。(プロキシ、キャッシュなど)があります。HTTPメッセージは、クライアントから仲介装置を経由して、オリジンサーバー（またはその逆）にホップ・バイ・ホップで転送されます。
- 場合によっては、隣接する2つのHTTPアプリケーションが、共有された コネクションにオプションセットを適用したい場合があります。HTTP Connection ヘッダーフィールドには、他のコネクションに伝搬されないコネクションのオプションを指定するコネクショントークンがコンマで区切られて表示されます。例えば、次のメッセージを送信した後に閉じなければならないコネクションは、Connection: closeで示されます。Connectionヘッダーには、3つの異なるタイプのトークンが含まれているため、混乱することがあります。

  - HTTP ヘッダーフィールド名（この接続のみに関連するヘッダーのリスト）
  - 任意のトークンの値：この接続の非標準的なオプションを示します。
  - closeという値は、接続が完了したときに永続的な接続が閉じられることを示します。

- ConnectionトークンにHTTPヘッダーフィールド名が含まれている場合、そのヘッダーフィールドには接続固有の情報が含まれており、転送してはいけません。Connection ヘッダーに記載されているヘッダーフィールドは、メッセージを転送する前に削除する必要があります。ホップバイホップのヘッダー名を Connection ヘッダーに置くことは、「ヘッダーの保護」として知られています。これは、Connection ヘッダーが、ローカルヘッダーの偶発的な転送から保護するためです。その例を図4-9に示します。
- HTTP アプリケーションが Connection ヘッダーを持つメッセージを受信すると、受信者は、送信者が要求したすべてのオプションを解析して適用します。その後、Connection ヘッダーと Connection ヘッダーに記載されているすべてのヘッダーを削除してから、メッセージを次のホップに転送します。さらに、Connectionヘッダーの値としてリストアップされていないが、プロキシされてはならないいくつかのhop-by-hopヘッダーがあります。これらには、Proxy-Authenticate、Proxy-Connection、Transfer-Encoding、および Upgrade が含まれます。Connectionヘッダーの詳細については、付録Cを参照してください。

### 4.3.2 Serial Transaction Delays
- TCPのパフォーマンスの遅延は、接続が単純に管理されている場合（シリアルローディング）、累積することがあります。
- HTTP接続のパフォーマンスを向上させるために、いくつかの最新の技術があります。次のいくつかのセクションでは、そのような技術のうち4つについて説明します。
  - Parallel connections：複数のTCPコネクションで同時にHTTPリクエストを行う 
  - Persistent connections：TCPコネクションを再利用することで、接続/終了時の遅延を解消
  - Pipelined connections：共有されたTCPコネクション上で、同時にHTTPリクエストを実行
  - Multiplexed connections：リクエストとレスポンスのチャンクをインターリーブする（実験的）

## 4.4 Parallel Connections
- HTTPでは、図4-11に示すように、クライアントが複数のコネクションを開き、複数のHTTPトランザクションを並行して実行することができます。この例では，4つの埋め込み画像が並行して読み込まれ，各トランザクションが独自のTCPコネクションを取得しています。

### 4.4.1 Parallel Connections May Make Pages Load Faster
- 埋め込みオブジェクトで構成された複合ページは、単一の接続によるデッドタイムと帯域幅の制限を利用すると、より速く読み込まれることがあります。

### 4.4.2 Parallel Connections Are Not Always Faster
- しかし、並列接続の方が速いといっても、必ずしも速いとは限りません。クライアントのネットワーク帯域幅が狭い場合（例えば、28.8Kbpsのモデムでインターネットに接続しているブラウザなど）、ほとんどの時間がデータの転送だけに費やされてしまうことがあります。このような状況では、高速なサーバーへの1つのHTTPトランザクションが、利用可能なモデムの帯域幅のすべてを簡単に消費してしまいます。複数のオブジェクトを並行してロードする場合、各オブジェクトは限られた帯域幅を奪い合うことになるため、各オブジェクトのロード速度は比例して遅くなり、パフォーマンス上の利点はほとんどありません
- また、多数のオープンコネクションは大量のメモリを消費し、それ自体がパフォーマンス問題を引き起こす可能性があります。複雑なWebページでは、数十から数百のオブジェクトが埋め込まれている場合があります。クライアントは何百もの接続を開くことができるかもしれませんが、ウェブサーバーは他の多くのユーザーのリクエストを同時に処理していることが多いため、その状況を望むサーバーはほとんどいないでしょう。100人のユーザーが同時に100個の接続を開くと、サーバーには1万個の接続の負担がかかります。これは、サーバーの大幅なスローダウンの原因となります。このような状況は、高負荷のプロキシについても同様です。実際には、ブラウザは並列接続を使用しますが、並列接続の総数は少数（多くは4）に制限されています。サーバーは、特定のクライアントからの過剰な接続を自由に閉じることができます。

### 4.4.3 Parallel Connections May "Feel" Faster
- なるほど、並列接続をすれば必ずページの読み込みが速くなるわけではありません。しかし、実際にページの転送速度が速くならなくても、先に述べたように、並列接続によって、ユーザーがページの読み込みが速くなったと感じることはよくあります。人間は、たとえストップウォッチで実際にページのダウンロード時間の合計が遅くなったとしても、画面全体でたくさんのアクションが行われていると、ウェブページの読み込みが速くなったと感じるのです 

## 4.5 Persistent Connections
- ウェブクライアントは、しばしば同じサイトへの接続を開きます。例えば、Webページに埋め込まれている画像のほとんどは、同じWebサイトから来ていることが多く、他のオブジェクトへのハイパーリンクのかなりの数が同じサイトを指しています。このように、あるサーバーにHTTPリクエストを開始したアプリケーションは、近い将来、そのサーバーにさらにリクエストを行う可能性があります（例えば、インライン画像を取得するために）。この性質をサイトロカリティといいます。
- このような理由から、HTTP/1.1 (およびHTTP/1.0の拡張版) では、HTTPデバイスが、トランザクションが完了した後もTCPコネクションを開いたままにしておき、将来のHTTPリクエストに既存のコネクションを再利用できるようになっています。トランザクションが完了した後も開かれているTCPコネクションは、持続的なコネクションと呼ばれます。非持続的な接続は、各トランザクションの後に閉じられます。持続的な接続は、クライアントまたはサーバのいずれかが接続を閉じると決定するまで、トランザクションを超えて開かれたままになります。
- 対象となるサーバーに対してすでにオープンしているアイドル状態の持続的な接続を再利用することで、遅い接続設定を回避することができます。また、すでに開いている接続を利用することで、開始時に時間のかかる輻輳適応フェーズを回避でき、より高速なデータ転送が可能になります。

### 4.5.1 Persistent Versus Parallel Connections
- 並列接続は速いが欠点もあった。
  - 各トランザクションが新しいコネクションを開閉するため、時間と帯域幅を消費する
  - それぞれの新しいコネクションはTCPスロースタートのためにパフォーマンスが低下する
  - 開いている並列接続数には実用上の制限がある
- 持続的な接続は、並列接続に比べていくつかの利点があります。接続確立の遅延とオーバーヘッドを減らし、接続を調整済みの状態に保ち、潜在的なオープンコネクションの数を減らすことができます。しかし、持続的接続は慎重に管理する必要があります。そうしないと、多数のアイドル接続が蓄積され、ローカルリソースやリモートクライアントおよびサーバーのリソースを消費してしまう可能性があります。
- 持続的な接続は、並列接続と組み合わせて使用すると最も効果的です。現在、多くのウェブアプリケーションでは、少数の並列接続を開き、それぞれを持続的に使用しています。持続的接続には、古い HTTP/1.0+ の "keep-alive "接続と、新しい HTTP/1.1 の "persistent "接続の2種類があります。次のいくつかのセクションでは、この2つのタイプについて説明します。

### 4.5.2 HTTP/1.0+ Keep-Alive Connections
- 多くのHTTP/1.0ブラウザやサーバーは、（1996年頃から）キープアライブ接続と呼ばれる初期の実験的なタイプの持続的な接続をサポートするように拡張されました。この初期の持続的接続には、相互運用性の設計上の問題があり、後のHTTP/1.1の改訂で修正されましたが、多くのクライアントやサーバーは今でもこの初期のキープアライブ接続を使用しています。
- 図4-13は、シリアル接続による4つのHTTPトランザクションのタイムラインと、単一の持続的接続による同じトランザクションのタイムラインを比較したものです。タイムラインが短縮されているのは、コネクトとクローズのオーバーヘッドが取り除かれているからです[16]。

### 4.5.3 Keep-Alive Operation
- Keep-alive は非推奨で、現在の HTTP/1.1 仕様では文書化されていません。しかし、Keep-alive ハンドシェイクはブラウザやサーバで比較的よく使われていますので、HTTP 実装者は相互運用の準備をしておく必要があります。ここでは、キープアライブの動作について簡単に説明します。keep-alive ハンドシェイクについてのより詳細な説明は、古いバージョンの HTTP/1.1 仕様 (RFC 2068 など) を参照してください。
- HTTP/1.0 のキープアライブ接続を実装するクライアントは、Connection:Keep-Alive リクエストヘッダを含めることで、接続を維持することを要求できます。
- サーバは、次のリクエストに対して接続を維持することを希望する場合は、同じヘッダをレスポンスに含めて応答します（図4-14参照）。応答に Connection: keep-alive ヘッダがない場合、クライアントは、サーバが keep-alive をサポートしておらず、応答メッセージが返送された時点でサーバが接続を終了するものと想定します。

### 4.5.4 Keep-Alive Options
- keep-aliveヘッダーは、接続を維持するための単なる要求であることに注意してください。クライアントとサーバーは、keep-aliveセッションが要求されても、それに同意する必要はありません。クライアントとサーバーは、アイドル状態のkeep-alive接続をいつでも閉じることができ、keep-alive接続で処理されるトランザクションの数を自由に制限することができます。
Keep-Aliveの動作は、Keep-Alive一般ヘッダで指定されるコンマ区切りのオプションによって調整できます。

  - timeoutパラメータは、Keep-Aliveレスポンスヘッダで送信されます。このパラメータは、サーバが接続を維持する可能性のある時間を推定します。これは保証されるものではありません。
  - max パラメーターは、Keep-Alive 応答ヘッダーで送信されます。これは、サーバーがあと何回のHTTPトランザクションの間、接続を維持できるかを示します。これは保証されるものではありません。
  - Keep-Alive ヘッダーは、主に診断やデバッグを目的とした、任意の未処理属性もサポートしています。構文は name [= value] です。

- Keep-Alive ヘッダーは完全にオプションですが、Connection.Keep-Alive も存在する場合にのみ許可されます。

### 4.5.5 Keep-Alive Connection Restrictions and Rules

### 4.5.6 Keep-Alive and Dumb Proxies
- ウェブクライアントのConnection: Keep-Aliveヘッダーは、クライアントから出て行く1つのTCPリンクだけに影響を与えることを目的としています。これが、「コネクション」ヘッダーと名付けられた理由です。クライアントがWebサーバーと通信している場合、クライアントはConnection: Keep-Aliveヘッダを送信して、キープアライブを希望することをサーバに伝えます。
- サーバーは、キープアライブをサポートしている場合はConnection: Keep-Aliveヘッダーを送り返し、サポートしていない場合は送らない。

#### 4.5.6.1 The Connection header and blind relays
- 問題はプロキシにあります。特に、Connectionヘッダを理解しておらず、プロキシ処理を行う前にこのヘッダを削除する必要があることを知らないプロキシです。古いプロキシやシンプルなプロキシの多くは、Connectionヘッダを特別に処理することなく、あるコネクションから別のコネクションへとバイトをトンネリングするブラインドリレーとして動作します。
- プロキシがConnectionヘッダーを知らないことにより、keep-alive接続をしようとするとハングアップが起こる。

#### 4.5.6.2 Proxies and hop-by-hop headers
- このようなプロキシのミスコミュニケーションを避けるために、最近のプロキシはConnectionヘッダーやConnectionの値の中に名前が出てくるヘッダーを決してプロキシしてはいけません。つまり、プロキシが Connection: Keep-Aliveヘッダを受け取った場合、プロキシはConnectionヘッダもKeep-Aliveという名前のヘッダもプロキシしてはいけません。
- さらに、Connectionヘッダーの値としてリストされていないが、プロキシしたり、キャッシュ応答として提供してはならないいくつかのhop-by-hopヘッダーがある。これには、ProxyAuthenticate、Proxy-Connection、Transfer-Encoding、および Upgrade が含まれます。詳細については、4.3.1項を参照してください。

### 4.5.7 The Proxy-Connection Hack
- ネットスケープ社のブラウザとプロキシの実装者たちは、ブラインドリレーの問題を解決するために、すべてのウェブアプリケーションが高度なバージョンのHTTPをサポートする必要のない、巧妙な回避策を提案した。この回避策では、Proxy-Connectionと呼ばれる新しいヘッダを導入し、クライアントの直後に介在する単一のブラインドリレーの問題を解決しましたが、他のすべての状況を解決することはできませんでした。
- Proxy-Connectionは、最近のブラウザではプロキシが明示的に設定されている場合に実装され、多くのプロキシが理解しています。ダムプロキシが問題になるのは、Connection:Keep-Aliveなどのhop-by-hopヘッダをやみくもに転送するからだということです。
- ホップバイホップヘッダは、その単一の特定の接続にのみ関連しており、転送してはいけません。これは、転送されたヘッダが下流のサーバによって、プロキシ自身が接続を制御するための要求であると誤解された場合に問題となります。
- ネットスケープの回避策では、ブラウザは公式にサポートされている有名なConnectionヘッダーの代わりに、非標準のProxy-Connection拡張ヘッダーをプロキシに送信します。プロキシがブラインド・リレーの場合、プロキシは無意味なProxy-Connectionヘッダをwebサーバに中継し、webサーバはそのヘッダを無害に無視します。しかし、プロキシがスマートプロキシ(持続的な接続ハンドシェイクを理解できる)であれば、無意味なProxy-ConnectionヘッダをConnectionヘッダに置き換え、それをサーバに送信することで望ましい効果を得ることができます。
- この方式は、クライアントとサーバーの間にプロキシが1台しかない場合に有効だが、ダムプロキシの両側にスマートプロキシがある場合、再び問題が出てくる。
- さらに、ファイアウォール、インターセプトキャッシュ、リバースプロキシサーバアクセラレータなど、「見えない」プロキシがネットワーク上に登場することが非常に多くなっています。これらのデバイスはブラウザからは見えないため、ブラウザはProxy-Connectionヘッダを送信しません。透過的なWebアプリケーションでは、持続的な接続を正しく実装することが重要です。

### 4.5.8 HTTP/1.1 Persistent Connections
- HTTP/1.1では、キープアライブ接続のサポートを段階的に廃止し、代わりに持続的接続と呼ばれる改良された設計を採用しました。持続的接続の目的は keep-alive 接続と同じですが、メカニズムの動作が改善されています。
- HTTP/1.0+ のキープアライブ接続とは異なり、HTTP/1.1 の持続的な接続はデフォルトで有効です。
- HTTP/1.1 は、他に指示がない限り、すべての接続が持続的であると仮定します。HTTP/1.1 アプリケーションは、トランザクションの完了後に接続を閉じることを示すために、メッセージに Connection: close ヘッダを明示的に追加する必要があります。これは、キープアライブ接続が任意であるか、完全にサポートされていなかった以前のバージョンの HTTP プロトコルとの大きな違いです。
- HTTP/1.1 クライアントは、レスポンスに Connection: close ヘッダーが含まれていない限り、レスポンス後も HTTP/1.1 コネクションが開いたままであることを想定します。しかし、クライアントやサーバーは、いつでもアイドル状態のコネクションを閉じることができます。Connection: close を送信しないことは、サーバーがコネクションを永遠に開いたままにすることを約束するものではありません。

### 4.5.9 Persistent Connection Restrictions and Rules
- Connection: close request headerを送信した後、クライアントはそのコネクション上でそれ以上のリクエストを送信することはできません。
- クライアントがそのコネクション上で他のリクエストを送りたくない場合は、最終リクエストの中でConnection: close request headerを送るべきです。
- コネクション上のすべてのメッセージが、正しく自己定義されたメッセージ長を持つ場合のみ、コネクションを持続させることができます。すなわち、エンティティボディが正しい Content-Length を持つか、chunked transfer エンコーディングでエンコードされていなければなりません。
- HTTP/1.1 プロキシは、クライアントとサーバーとの間の永続的な接続を別々に管理しなければならず、各永続的な接続は単一のトランスポートホップに適用される。
- HTTP/1.1 プロキシサーバーは、クライアントの能力について何かを知らない限り、HTTP/1.0 クライアントとの持続的な接続を確立すべきではありません (Connection ヘッダを転送する古いプロキシの問題のため)。
クライアントの能力を知らない限り、HTTP/1.0クライアントとの持続的な接続を確立してはいけません。これは実際には難しく、多くのベンダーがこのルールを曲げています。
- Connection ヘッダの値にかかわらず、HTTP/1.1 デバイスはいつでも接続を閉じることができますが、サーバーはメッセージ送信の途中で閉じることは避け、閉じる前に少なくとも 1 つのリクエストに応答する必要があります。
- HTTP/1.1 アプリケーションは、非同期のクローズから回復できなければなりません。クライアントは、蓄積されるような副作用がない限り、リクエストを再試行するべきです。
- クライアントは、レスポンス全体を受け取る前にコネクションがクローズした場合、リクエストが繰り返されると副作用が発生する可能性がない限り、リクエストを再試行する準備をしなければなりません。
- シングルユーザーのクライアントは、サーバーの過負荷を防ぐために、どのサーバーやプロキシに対しても最大で2つの持続的な接続を維持する必要があります。プロキシは、同時ユーザをサポートするためにサーバへのより多くの 接続を必要とするかもしれないので、サーバにアクセスしようとする ユーザがN人いる場合、プロキシはいかなるサーバまたは親プロキシに 対しても最大で2N個の接続を維持すべきである。

## 4.6 Pipelined Connections
- HTTP/1.1では、持続的な接続におけるオプションのリクエストパイプライニングが可能です。これは、キープアライブ接続よりもさらにパフォーマンスが向上します。複数のリクエストを、レスポンスの到着前に待ち受けることができます。最初のリクエストが地球の反対側にあるサーバーにネットワークを介してストリーミングされている間に、2番目と3番目のリクエストが進行します。これにより、ネットワークのラウンドトリップを減らすことができ、高レイテンシーのネットワーク環境でのパフォーマンスを向上させることができます。
- 図4-18a-cは、持続的な接続によってTCP接続の遅延を解消し、パイプライン化されたリクエスト（図4-18c）によって転送の遅延を解消する方法を示しています。
- パイプラインにはいくつかの制限があります。
  - HTTPクライアントは、接続が持続することを確認するまでパイプラインを使用してはいけません。
  - HTTP レスポンスは、リクエストと同じ順序で返されなければなりません。HTTP メッセージはシーケンス番号でタグ付けされていないため、レスポンスを順不同で受信した場合、レスポンスとリクエストを一致させる方法はありません。
  - HTTP クライアントは、接続がいつでも閉じられるように準備しておく必要があります。 HTTP クライアントは、いつでも接続を閉じることができるように準備し、終了しなかったパイプライン化されたリクエストをやり直す準備をしておく必要があります。クライアントが永続的な接続を開き、すぐに10個のリクエストを発行した場合、サーバーは例えば5個のリクエストだけを処理した後に自由に接続を閉じることができます。残りの5つのリクエストは失敗します。クライアントは、このような早すぎるクローズを処理して、リクエストを再発行することを望まなければなりません。
  - HTTP クライアントは、副作用のあるリクエスト（POST など）をパイプラインで処理すべきではありません。一般に、エラー時にパイプライン化すると、クライアントはパイプライン化された一連のリクエストのうち、どのリクエストがサーバーで実行されたかを知ることができません。POST のような非一時的なリクエストは安全に再試行できないため、エラー状態では一部のメソッドが実行されないというリスクがあります。

## 4.7 The Mysteries of Connection Close
- 接続管理、特にいつ、どのように接続を閉じるかということは、HTTPの実用的なブラックアートの1つです。この問題は、多くの開発者が最初に認識しているよりも微妙なもので、この問題について書かれたものはほとんどありません。

### 4.7.1 "At Will" Disconnection
- HTTP クライアント、サーバ、プロキシは、いつでも TCP トランスポート接続を閉じることができます。コネクションは通常、メッセージの最後で閉じられますが、エラー状態の時には、ヘッダー行の途中やその他の奇妙な場所で閉じられることがあります。
- この状況は、パイプライン化された持続的な接続でよく見られます。HTTPアプリケーションは、任意の期間後に永続的な接続を閉じることができます。例えば、持続的な接続がしばらくアイドル状態になった後、サーバーはその接続をシャットダウンすることができます。
- しかし、サーバーは、「アイドル」接続がサーバーによってシャットダウンされている間に、回線の反対側にいるクライアントがデータを送信しようとしていなかったことを確実に知ることはできません。これが起こると、クライアントはリクエストメッセージを書いている最中に接続エラーを確認します。

### 4.7.2 Content-Length and Truncation
- 各 HTTP レスポンスには、レスポンスボディのサイズを示す正確な Content-Length ヘッダーが必要です。古い HTTP サーバーの中には、データの実際の終了を示すサーバーのコネクションクローズに依存して、Content-Length ヘッダーを省略したり、誤った長さを含めたりするものがあります。
- クライアントやプロキシがコネクションクローズで終了する HTTP レスポンスを受け取り、実際に転送されたエンティティの長さが Content-Length と一致しない (または Content-Length がない) 場合、受信者は長さの正しさを疑うべきです。
- 受信者がキャッシュプロキシの場合、受信者は応答をキャッシュすべきではない(潜在的なエラーの将来的な複合化を最小限にするため)。プロキシは、セマンティックな透明性を維持するために、Content-Lengthの「修正」を試みることなく、疑わしいメッセージをそのまま転送すべきである。

### 4.7.3 Connection Close Tolerance, Retries, and Idempotency
- 接続は、エラーが発生していない状態でも、いつでも閉じることができます。HTTP アプリケーションは、予期せぬクローズを適切に処理する準備をしなければなりません。クライアントがトランザクションを実行しているときにトランスポート接続が閉じた場合、トランザクションに副作用がない限り、クライアントは接続を再度開き、1回だけ再試行する必要があります。
- パイプライン接続の場合、状況はさらに悪化します。クライアントは多数のリクエストをエンキューすることができますが、オリジンサーバーは接続を閉じることができ、多数のリクエストが処理されずに残り、再スケジューリングが必要になります。
- 副作用は重要です。あるリクエストデータが送信された後、レスポンスが返される前にコネクションがクローズされた場合、クライアントは、トランザクションのうちどれだけが実際にサーバによって呼び出されたかを100％確信することはできません。静的なHTMLページをGETするようなトランザクションは、何も変更せずに何度でも繰り返すことができます。他のトランザクション、例えばオンライン書店への注文のPOSTなどは繰り返すべきではありません、さもないと複数の注文を受ける危険性があります。
- トランザクションは、一度実行されても何度も実行されても同じ結果が得られる場合、冪等であると言えます。実装者は、GET、HEAD、PUT、DELETE、TRACE、OPTIONSの各メソッドがこの性質を持つと仮定することができます。
メソッドがこの性質を持っていると仮定することができます。 クライアントは（POSTのような）冪等でないリクエストをパイプラインで送るべきではありません。
- そうしないと、トランスポート接続の早期終了により、不確定な結果になる可能性があります。非冪等のリクエストを送信したい場合は、前のリクエストのレスポンスステータスを待つべきです。
- 非べき等のメソッドやシーケンスは自動的に再試行されてはならないが、ユーザエージェントは人間のオペレータにリクエストを再試行する選択肢を提供することができる。例えば、ほとんどのブラウザは、キャッシュされたPOSTレスポンスを再読み込みする際に、トランザクションを再度投稿するかどうかを尋ねるダイアログボックスを提供します。

### 4.7.4 Graceful Connection Close
- 図4-19に示すように、TCPコネクションは双方向である。TCPコネクションの各側には、データの読み書きのための入力キューと出力キューがあります。

#### 4.7.4.1 Full and half closes
- アプリケーションは、TCP の入力チャネルと出力チャネルのいずれか、または両方を閉じることができます。close()ソケット・コールは、TCP 接続の入力チャネルと出力チャネルの両方を閉じます。これは「フル・クローズ」と呼ばれ、図 4-20a に示されています。shutdown()ソケット・コールを使用すると、入力チャネルまたは出力チャネルを個別に閉じることができます。これは「ハーフクローズ」と呼ばれるもので、図 4-20b に示されています。

a. server full close
<--|
---|
b. server output half close (graceful close)
<--|
--->
c. server input half close
<---
---|

#### 4.7.4.2 TCP close and reset errors
- 単純なHTTPアプリケーションでは、フルクローズしか使用できません。しかし、アプリケーションが他の多くのタイプのHTTPクライアント、サーバー、プロキシと通信するようになったり、パイプラインによる持続的な接続を使用するようになると、相手が予期しない書き込みエラーを起こさないようにするために、ハーフクローズを使用することが重要になります。
- 一般的に、接続の出力チャネルを閉じることは常に安全です。接続の反対側にいるピアは、バッファからすべてのデータが読み込まれると、end-of-stream通知を受け取って、接続を閉じたことが通知されます。
- 接続の入力チャネルを閉じることは、相手側がこれ以上データを送る予定がないことがわかっている場合を除き、リスクが高くなります。相手側があなたの閉じた入力チャネルにデータを送信すると、オペレーティングシステムは、図4-21に示すように、TCPの「Connection reset by peer」メッセージを相手側のマシンに返します。ほとんどのオペレーティングシステムはこれを重大なエラーとして扱い、相手側がまだ読んでいないバッファリングされたデータを消去します。これは、パイプライン接続にとって非常に悪いことです。
- 持続的な接続でパイプライン化された10個のリクエストを送信し、レスポンスはすでに到着してオペレーティングシステムのバッファに置かれているとします（ただし、アプリケーションはまだ読んでいません）。ここで、あなたがリクエスト#11を送信したとします。しかし、サーバーはあなたがこの接続を十分に使用したと判断し、接続を閉じました。あなたのリクエスト#11は閉じたコネクションに到着し、あなたにリセットを返します。このリセットにより、入力バッファが消去されます。ようやくデータを読めるようになったとき、ピアエラーによるコネクションリセットが発生し、バッファリングされた未読のレスポンスデータは、その多くが正常にあなたのマシンに到着したにもかかわらず、失われてしまいます。

### 4.7.4.3 Graceful close
- HTTP仕様では、クライアントやサーバが予期せずに接続を閉じたい場合、「トランスポート接続にグレースフルクローズを発行する」ことが推奨されていますが、その方法については記述されていません。
- 一般的に、グレースフルクローズを実装するアプリケーションは、まず自分の出力チャンネルを閉じ、次に接続の反対側にいる相手が自分の出力チャンネルを閉じるのを待ちます。双方がもうデータを送信しないことを伝え終わったら（つまり、出力チャンネルを閉じたら）、リセットのリスクなしに、接続を完全に閉じることができます。
- 残念ながら、相手側がハーフクローズを実装しているかどうか、チェックしているかどうかは保証されていません。このため、gracefullyに閉じたいアプリケーションは、出力チャネルをハーフクローズし、入力チャネルの状態を定期的にチェックする必要があります（データの有無やストリームの終了を確認する）。あるタイムアウト時間内に入力チャネルがピアによってクローズされなかった場合、アプリケーションはリソースを節約するために強制的に接続をクローズすることができます。

# Part II: HTTP Architecture
- Ch5 ~ 10

# Ch5 Web Servers
- ウェブサーバは、1日に何十億ものウェブページを配信しています。天気予報を伝えたり、オンラインショッピングのカートを積み込んだり、懐かしい高校時代の友人を探したりしています。ウェブサーバは、World Wide Webの主力製品です。この章では、以下のことを説明します。

  - ソフトウェアおよびハードウェアのウェブサーバのさまざまな種類について説明します。
  - Perlで簡単な診断用Webサーバを書く方法を説明します。
  - ウェブサーバがどのようにHTTPトランザクションを処理するのか、順を追って説明します。

- 物事を具体的に説明するために、例ではApache Webサーバとその設定オプションを使用します。

## 5.1 Web Servers Come in All Shapes and Sizes
- Webサーバーは、HTTPリクエストを処理し、レスポンスを提供します。「Webサーバー」という言葉は、Webサーバーソフトウェアを指す場合と、Webページを提供するための専用のデバイスやコンピューターを指す場合があります。
- ウェブサーバーには、さまざまな種類、形、サイズがあります。些細な10行のPerlスクリプトのウェブサーバもあれば、50MBの安全なコマースエンジンもありますし、小さなカード型のサーバもあります。しかし、機能的な違いはあっても、すべてのウェブサーバはリソースに対するHTTPリクエストを受け取り、クライアントにコンテンツを提供します（図1-5を参照）。

### 5.1.1 Web Server Implementations
- Webサーバは、HTTPとそれに関連するTCPコネクションの処理を実装します。また、ウェブサーバーが提供するリソースを管理し、ウェブサーバーを設定、制御、強化するための管理機能を提供します。
- Webサーバーロジックは、HTTPプロトコルを実装し、Webリソースを管理し、Webサーバーの管理機能を提供します。Webサーバのロジックは、TCPコネクションの管理をOSと分担しています。
- オペレーティングシステムは、基礎となるコンピュータシステムのハードウェアの詳細を管理し、TCP/IPネットワークのサポート、ウェブリソースを保持するファイルシステム、および現在のコンピューティングアクティビティを制御するプロセス管理を提供します。
- Webサーバーにはさまざまな種類があります。

  - 一般的なコンピュータシステムに、汎用ソフトウェアのウェブサーバーをインストールして実行することができます。
  - ソフトウェアをインストールするのが面倒な場合は、ウェブサーバーアプライアンスを購入することができます。このアプライアンスは、ソフトウェアがあらかじめコンピュータにインストールされ、設定された状態で、スタイリッシュな筐体に収められています。
  - また、マイクロプロセッサの進歩により、少数のチップで構成された組み込み型のウェブサーバーを提供している企業もあり、コンシューマー機器の管理コンソールとしても最適です。

- それでは、それぞれのタイプの実装を見ていきましょう。

### 5.1.2 General-Purpose Software Web Servers
- 汎用ソフトウェアのウェブサーバーは、ネットワークに接続された標準的なコンピュータシステム上で動作する。オープンソースのソフトウェア（ApacheやW3CのJigsawなど）や商用ソフトウェア（MicrosoftやiPlanetのWebサーバーなど）を選択することができます。Webサーバーのソフトウェアは、ほぼすべてのコンピュータとOSに対応しています。
- 何万種類ものウェブサーバープログラム（カスタムメイドの特別な目的のウェブサーバーを含む）がありますが、ほとんどのウェブサーバーソフトウェアは、少数の組織から提供されています。
- 比率としてはApacheソフトウェアが多いとされる。

### 5.1.3 Web Server Appliances
- Webサーバーアプライアンスは、ソフトウェアとハードウェアがパッケージ化されたソリューションです。ベンダーは、ベンダーが選択したコンピュータプラットフォームにソフトウェアサーバーをあらかじめインストールし、ソフトウェアを事前に設定します。以下の例があります。
- Webサーバーアプライアンスの例としては、次のようなものがあります。

  - Sun/Cobalt RaQ Webアプライアンス (http://www.cobalt.com)
  - 東芝Magnia SG10 (http://www.toshiba.com)
  - IBM Whistle Webサーバーアプライアンス (http://www.whistle.com) 

- アプライアンスソリューションは、ソフトウェアのインストールや設定の必要性を排除し、多くの場合、管理を大幅に簡素化します。しかし、Webサーバーの柔軟性や機能性は低く、サーバーハードウェアの再利用やアップグレードも容易ではありません。

### 5.1.4 Embedded Web Servers
- 組み込み型サーバーは、プリンターや家電製品などのコンシューマー製品に組み込むことを目的とした小型のウェブサーバーです。
- 組込み型Webサーバを使用することで、ユーザは便利なWebブラウザのインターフェースを使用して、コンシューマ機器を管理することができます。
- 組み込み型Webサーバの中には、1平方インチ以下の大きさで実装できるものもありますが、通常は最小限の機能しか提供されていません。

## 5.2 A Minimal Perl Web Server
- フル機能のHTTPサーバーを構築するには、いくつかの作業が必要になります。Apacheウェブサーバのコア部分には5万行以上のコードがあり、オプションの処理モジュールを使えば、その数はもっと多くなります。
- これらのソフトウェアは、HTTP/1.1の機能をサポートするために必要です。リッチリソースサポート、バーチャルホスティング、アクセスコントロール、ロギング、コンフィギュレーション、モニタリング、パフォーマンス機能などです。とはいえ、最低限の機能を備えたHTTPサーバは、30行以下のPerlで作ることができます。（例5-1 type-o-serveというPerlのプログラム）

## 5.3 What Real Web Servers Do
- 最新の商用Webサーバは例5-1よりもっと複雑ですが、図5-3に示すように、いくつかの一般的なタスクを実行します。

  1. 接続の設定：クライアントの接続を受け入れるか、クライアントが不要な場合は閉じる。
  2. リクエストの受信：ネットワークからのHTTPリクエストメッセージを読み込みます。
  3. リクエストの処理：リクエストメッセージを解釈してアクションを起こす。
  4. Access resource：メッセージで指定されたリソースにアクセスする。
  5. Construct response：正しいヘッダーを持つ HTTP レスポンスメッセージを作成する。
  6. レスポンスの送信：レスポンスをクライアントに返信します。
  7. トランザクションの記録：完了したトランザクションに関するメモをログファイルに記録します。

- 次の7つのセクションでは、ウェブサーバーがこれらの基本的なタスクをどのように実行するかを説明します。

## 5.4 Step 1: Accepting Client Connections
- クライアントは、サーバーとの持続的接続がすでに開かれている場合は、その接続を使用してリクエストを送信することができます。そうでない場合は、クライアントはサーバーへの新しい接続を開く必要があります

### 5.4.1 Handling New Connections
- クライアントがウェブサーバへのTCP接続を要求すると、ウェブサーバは接続を確立し、TCP接続からIPアドレスを抽出して、接続の相手方がどのクライアントであるかを判断します。 新しい接続が確立されて受け入れられると、サーバは新しい接続を既存のウェブサーバの接続リストに追加し、接続上のデータを監視する準備をします。
- ウェブサーバは、どのような接続も自由に拒否し、直ちに閉鎖することができます。ウェブサーバの中には、クライアントのIPアドレスやホスト名が不正なものであったり、既知の悪意のあるクライアントであったりするために、接続を閉じるものもあります。その他の識別技術を使用することもできます。

### 5.4.2 Client Hostname Identification
- ほとんどのウェブサーバは、"リバースDNS "を使用して、クライアントのIPアドレスをクライアントのホスト名に変換するように設定できます。ウェブサーバは、クライアントのホスト名を利用して、詳細なアクセス制御やロギングを行うことができます。ただし、ホスト名の検索には非常に長い時間がかかるため、Webトランザクションの速度が低下する可能性があることに注意してください。大容量のウェブサーバの多くは、ホスト名解決を無効にしたり、特定のコンテンツに対してのみ有効にしたりしています。
- Apache では Hostname Lookups 設定ディレクティブを使ってホスト名検索を有効にすることができます。（例ではHTML、CGIリソースが設定されているが、これはクライアントがこれらの種類のリソース取得を依頼した場合にはクライアントのIPをホスト名に変換するということか？）

### 5.4.3 Determining the Client User Through ident
- 一部のウェブサーバーは、IETFのidentプロトコルをサポートしています。identプロトコルでは、どのユーザーがHTTP接続を開始したかをサーバーが知ることができます。この情報は、ウェブサーバのログ収集に特に役立ちます。一般的なCommon Log Formatの第2フィールドには、各HTTPリクエストのidentユーザー名が含まれています。
- クライアントがidentプロトコルをサポートしている場合、クライアントはTCPポート113でidentリクエストを待ち受けます。図5-4にidentプロトコルの仕組みを示します。図5-4aでは、クライアントがHTTPコネクションを開きます。サーバは、クライアントのidentdサーバポート（113）に戻る独自の接続を開き、新しい接続（クライアントとサーバのポート番号で指定）に対応するユーザ名を求める単純なリクエストを送信し、ユーザ名を含む応答をクライアントから取得します。
- identは組織内では機能しますが、公共のインターネット上では、以下のような多くの理由でうまく機能しません。

  - 多くのクライアントPCでは、Identification Protocolのデーモンソフトウェアであるidentdが動作しません。
  - identプロトコルは、HTTPトランザクションを大幅に遅延させます。
  - 多くのファイアウォールがidentのトラフィックの受信を許可しない。
  - identプロトコルは安全ではなく、偽造も容易です。
  - identプロトコルは、仮想IPアドレスをうまくサポートできません。
  - クライアントのユーザ名を公開することには、プライバシーの問題があります。

- ApacheのIdentityCheck onディレクティブを使って、Identルックアップを使うようにApacheのウェブサーバに伝えることができます。ident の情報が得られない場合、Apache は ident のログフィールドをハイフン (-) で埋めます。Common Log Format のログファイルは、ID 情報がないため、通常 2 番目のフィールドにハイフンが含まれています。

## 5.5 Step 2: Receiving Request Messages
- コネクションにデータが到着すると、ウェブサーバーはネットワークコネクションからデータを読み取って リクエストメッセージの一部を解析します（図5-5）。
- リクエストメッセージを解析する際、ウェブサーバーは以下の作業を行います。

  - リクエスト行を解析して，リクエストメソッド，指定されたリソース識別子（URI），バージョン番号を探し[3]，それぞれを1つのスペースで区切り，最後にCRLF（carriage-return line-feed）シーケンスで終了する[4]。
    - [3] HTTPの初期バージョンであるHTTP/0.9は、バージョン番号をサポートしていません。一部のウェブサーバーはバージョン番号の欠落をサポートしており、メッセージをHTTP/0.9のリクエストとして解釈します。
    - [4] クライアントの中には、LF を行末のターミネーターとして誤って送信するものがあるため、多くのウェブサーバーは行末のシーケンスとして LF または CRLF をサポートしています。
  - CRLF で終わるメッセージヘッダーを読み取ります。
  - CRLF で終わるヘッダの空行を検出します（存在する場合）。
  - リクエストボディがあれば読み取る（Content-Length ヘッダーで指定された長さ）。

- リクエストメッセージを解析する際、ウェブサーバーはネットワークから不規則に入力データを受け取ります。ネットワーク接続はどの時点でも失速する可能性があります。Web サーバーは、ネットワークからデータを読み取り、メッセージの部分的なデータを一時的にメモリに格納してから、メッセージを解析して意味を理解するのに十分なデータを受け取る必要があります。

### 5.5.1 Internal Representations of Messages
- ウェブサーバの中には、リクエストメッセージを内部のデータ構造に格納して、メッセージの操作を容易にしているものもあります。例えば、データ構造にはリクエストメッセージの各部分のポインタと長さが格納され、ヘッダは高速ルックアップテーブルに格納され、特定のヘッダの特定の値に素早くアクセスできるようになっているかもしれません（図5-6）。

### 5.5.2 Connection Input/Output Processing Architectures
- 高性能なウェブサーバは、数千の同時接続をサポートしています。これらの接続により、ウェブサーバは世界中のクライアントと通信することができ、各クライアントはサーバに対して1つまたは複数の接続を開いています。これらの接続の中には、ウェブサーバーに素早くリクエストを送信しているものもあれば、ゆっくりと、あるいはまれにしかリクエストを送信しないものもあります。また、将来の活動を静かに待っているアイドル状態の接続もあります。
- リクエストはいつでも発生する可能性があるため、Webサーバは常に新しいWebリクエストを監視しています。図5-7に示すように、ウェブサーバのアーキテクチャによって、リクエストの処理方法は異なります。

- シングルスレッドのウェブサーバ（図5-7a）
  - シングルスレッドのウェブサーバは、一度に1つのリクエストを完了するまで処理します。トランザクションが完了すると、次の接続が処理されます。このアーキテクチャは実装が簡単ですが、処理中は他のすべての接続が無視されます。これは深刻なパフォーマンス問題を引き起こすので、負荷の低いサーバーやtype-o-serveのような診断ツールにのみ適しています。

- マルチプロセス・マルチスレッドWebサーバ（図5-7b）
  - マルチプロセス・マルチスレッドWebサーバは、複数のプロセスや効率の良いスレッドを使用して、リクエストを同時に処理します[5]。スレッド/プロセスは、必要に応じて作成される場合もあれば、事前に作成される場合もあります[6]。接続ごとにスレッドやプロセスを割り当てるサーバもありますが、サーバが数百、数千、あるいは数万の同時接続を処理する場合、結果としてプロセスやスレッドの数が多くなり、メモリやシステムリソースを消費してしまう可能性があります。そのため、マルチスレッド対応のウェブサーバーの多くは、スレッド/プロセスの最大数に制限を設けています。
  - [5]プロセスとは、個々のプログラムの制御の流れであり、独自の変数群を持つものです。スレッドは、プロセスのより高速で効率的なバージョンです。スレッドもプロセスも、1つのプログラムで複数のことを同時に行うことができます。説明を簡単にするために、ここではプロセスとスレッドを同じように扱います。しかし、性能の違いから、多くの高性能サーバーはマルチプロセスとマルチスレッドの両方を採用している。
  - [6]スレッドをあらかじめ作成しておくシステムを「ワーカープール」と呼びますが、これはスレッドの集合体がプールで仕事を待っているからです。

- 多重化されたI/Oサーバー（図5-7c）
  - 大量の接続をサポートするために、多くのウェブサーバは多重化アーキテクチャを採用しています。多重化されたアーキテクチャでは、すべての接続が同時に監視され、活動が行われます。接続の状態が変化したとき（データが利用可能になったときや、エラー状態が発生したときなど）、その接続に対して少量の処理が行われ、その処理が完了すると、その接続は次の状態変化のために開いている接続リストに戻される。処理が完了すると、次の状態変更のために接続がオープンリストに戻されます。処理すべきことがある場合にのみ、接続上で作業が行われ、スレッドやプロセスがアイドル状態の接続を待つことはありません。

- 多重化されたマルチスレッドのWebサーバ（図5-7d）
  - マルチスレッドとマルチプレックスを組み合わせて、コンピュータ・プラットフォームの複数のCPUを活用するシステムもあります。複数のスレッド（多くの場合、物理的なプロセッサごとに1つ）がそれぞれ開いている接続（または開いている接続のサブセット）を監視し、各接続に対して少量の作業を行います。

## 5.6 Step 3: Processing Requests
- Web サーバーは、リクエストを受信すると、メソッド、リソース、ヘッダー、オプションのボディを使用してリクエストを処理できます。
- 一部のメソッド（POSTなど）では、リクエストメッセージにエンティティボディデータを必要とします。その他のメソッド (例: OPTIONS) は、リクエストボディを許可しますが、必要としません。いくつかのメソッド (例: GET) は、リクエスト・メッセージ内のエンティティ・ボディ・データを禁止しています。
- ここでは、リクエスト処理については触れません。なぜなら、この本の残りの部分のほとんどの章で扱われるからです。

## 5.7 Step 4: Mapping and Accessing Resources
- ウェブサーバはリソースサーバであり、HTMLページやJPEG画像などの事前に作成されたコンテンツや、サーバ上で動作するリソース生成アプリケーションからの動的コンテンツを配信する。
- ウェブサーバは、クライアントにコンテンツを配信する前に、リクエストメッセージのURIをウェブサーバ上の適切なコンテンツまたはコンテンツジェネレータにマッピングすることで、コンテンツのソースを特定する必要があります。

### 5.7.1 Docroots
- ウェブサーバはさまざまな種類のリソースマッピングをサポートしていますが、最もシンプルなリソースマッピングは、リクエストURIを使ってウェブサーバのファイルシステム内のファイル名を指定するものです。通常、ウェブサーバーのファイルシステムには、ウェブコンテンツ用の特別なフォルダが用意されています。このフォルダはドキュメントルート（docroot）と呼ばれています。Web サーバーはリクエストメッセージから URI を受け取り、ドキュメントルートに追加します。
- 図 5-8 では、/specials/saw-blade.gif のリクエストが届いています。この例の Web サーバはドキュメントルート /usr/local/httpd/files を持っています。Web サーバーはファイル /usr/local/httpd/files/specials/sawblade.gif を返します。

- Apache Web サーバーのドキュメントルートを設定するには、httpd.conf コンフィギュレーションファイルに DocumentRoot 行を追加します。

```
DocumentRoot /usr/local/httpd/files
```

- サーバーは、相対URLがドキュメントルートから戻ってきて、ファイルシステムの他の部分を公開しないように注意します。例えば、ほとんどの成熟したウェブサーバーは、次のURIがJoe's Hardwareのドキュメントルートより上のファイルを見ることを許可しません。 http://www.joes-hardware.com/../

#### 5.7.1.1 Virtually hosted docroots
- 仮想ホスト型Webサーバーは、複数のWebサイトを同一のWebサーバー上でホストし、各サイトにサーバー上の個別のドキュメントルートを与えます。仮想ホスト型Webサーバーは、URIやHostヘッダーのIPアドレスやホスト名から、使用する正しいドキュメントルートを特定します。このようにして、同じWebサーバーでホストされている2つのWebサイトは、リクエストURIが同じであっても、完全に異なるコンテンツを持つことができます。
- 図5-9では、サーバーは www.joes-hardware.com と www.marys-antiques.com という2つのサイトをホストしています。サーバーは、HTTP Host ヘッダーを使用して、または異なる IP アドレスから Web サイトを識別できます。

```
-- リクエストA
GET /index.html HTTP/1.0
Host: www.joes-hardware.com

-- リクエストB
GET /index.htmld HTTP/1.0
Host: ww.marys-antiques.com
```
  - リクエストAが到着すると、サーバーは/docs/joe/index.htmlのファイルをフェッチします。
  - リクエストBが到着すると、サーバーは/docs/mary/index.htmlのファイルをフェッチします。

- ほとんどのウェブサーバでは、仮想ホストされたドキュメントを設定するのは簡単です。一般的な Apache Web サーバーでは、仮想 Webサイトごとに VirtualHost ブロックを設定し、各仮想サーバーの DocumentRoot を含める必要があります（例 5-3）。
- バーチャル・ホスティングの詳細については、セクション18.2を参照してください。

#### 5.7.1.2 User home directory docroots
- docrootsのもう一つの一般的な使い方は、ウェブサーバー上にプライベートなウェブサイトを提供することです。典型的な規約では、パスがスラッシュとチルダ（/~）で始まり、ユーザー名が続くURIを、そのユーザーのプライベートドキュメントルートにマッピングします。プライベートドキュメントルートは、多くの場合、そのユーザーのホームディレクトリ内のpublic_htmlというフォルダですが、別の構成にすることもできます（図5-10）。

### 5.7.2 Directory Listings
- Webサーバーは、パスがファイルではなくディレクトリに解決されるディレクトリURLのリクエストを受け取ることができます。ほとんどのウェブサーバーは、クライアントがディレクトリURLをリクエストしたときに、いくつかの異なるアクションを取るように設定できます。ディレクトリURLを要求した場合、多くのウェブサーバは以下のような動作をします。

  - エラーを返す。
  - ディレクトリではなく、特別なデフォルトの「インデックスファイル」を返す。
  - ディレクトリをスキャンして、その内容を含むHTMLページを返す。

- ほとんどのウェブサーバは、ディレクトリを表すために、ディレクトリ内にindex.htmlまたはindex.htmという名前のファイルを探します。ユーザーがあるディレクトリのURLを要求したときに、そのディレクトリにindex.html（またはindex.htm）という名前のファイルがあれば、サーバーはそのファイルの内容を返します。
- Apacheウェブサーバでは、DirectoryIndex設定ディレクティブを使って、デフォルトのディレクトリファイルとして解釈されるファイル名のセットを設定することができます。DirectoryIndex ディレクティブは、ディレクトリ・インデックス・ファイルとして機能するすべてのファイル名を、優先順にリストアップします。以下の設定行は、ディレクトリ URL のリクエストに応答して、Apache がディレクトリを検索して、リストされたファイルを探すようにします。

```
DirectoryIndex index.html index.htm home.html home.htm index.cgi 
```

- ユーザがディレクトリ URI を要求したときにデフォルトのインデックスファイルが存在せず、ディレクトリインデックスが無効になっていない場合、多くの Web サーバは、そのディレクトリ内のファイルの一覧、各ファイルのサイズと更新日、各ファイルへの URI リンクを含む HTML ファイルを自動的に返します。このファイル一覧は便利ですが、おせっかいな人が通常は見つけられないようなファイルをウェブサーバ上で見つけてしまう可能性があります。
- ディレクトリインデックスファイルの自動生成は、Apache ディレクティブで無効にすることができます。 `Options -Indexes`

### 5.7.3 Dynamic Content Resource Mapping
- Webサーバは、URIをダイナミックリソース、つまり必要に応じてコンテンツを生成するプログラムにマッピングすることもできます（図5-11）。実際、アプリケーション・サーバと呼ばれるウェブ・サーバのクラスは、ウェブ・サーバと高度なバックエンド・アプリケーションとを接続します。ウェブサーバは、あるリソースが動的リソースであること、動的コンテンツ生成プログラムがどこにあるか、そしてそのプログラムをどのように実行するかを知る必要があります。ほとんどのウェブサーバは、動的リソースを識別してマッピングするための基本的なメカニズムを備えています。
- Apache では、URI のpathnameコンポーネントを実行可能なプログラムのディレクトリに マップすることができます。サーバは、実行可能なパス成分を持つ URI のリクエストを受け取ると、対応するサーバのディレクトリにあるプログラムを実行しようとします。例えば、次の Apache 設定ディレクティブは、パスが /cgi-bin/ で始まるすべての URI が /usr/local/etc/httpd/cgi-programs/ ディレクトリにある対応するプログラムを実行することを指定しています。

```
ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-programs/
```

- Apache では、実行ファイルを特別なファイル拡張子でマークすることもできます。この方法では、実行可能なスクリプトをどのディレクトリにも置くことができます。以下のApacheの設定ディレクティブは、.cgiで終わるすべてのウェブリソースを実行するように指定しています。

```
AddHandler cgi-script .cgi
```

- CGI は、サーバサイドアプリケーションを実行するための初期のシンプルで人気のあるインターフェイスです。最近のアプリケーションサーバは、Microsoft の Active Server Pages や Java servlet など、より強力で効率的なサーバサイドのダイナミックコンテンツをサポートしています。

### 5.7.4 Server-Side Includes (SSI)
- 多くのウェブサーバーは、サーバーサイドインクルードをサポートしています。リソースにサーバーサイドインクルードのフラグが立っている場合、サーバーはクライアントに送信する前にリソースのコンテンツを処理します。
- リソースのコンテンツは、変数名や埋め込まれたスクリプトなどの特殊なパターン（多くの場合、特別なHTMLコメントの中に含まれています）をスキャンします。特殊なパターンは、変数の値や、実行可能なスクリプトの出力に置き換えられます。これにより、簡単に動的なコンテンツを作成することができます。

### 5.7.5 Access Controls
- ウェブサーバは、特定のリソースにアクセス制御を割り当てることもできます。アクセス制御されたリソースへのリクエストが到着すると、ウェブサーバーはクライアントのIPアドレスに基づいてアクセスを制御したり、リソースへのアクセスを得るためにパスワードチャレンジを発行したりすることができます。
- HTTP認証の詳細については、第12章を参照してください。

## 5.8 Step 5: Building Responses
- Webサーバーは、リソースを特定すると、リクエストメソッドに記述されたアクションを実行し、レスポンスメッセージを返します。応答メッセージには、応答ステータスコード、応答ヘッダー、および応答ボディ（生成された場合）が含まれます。HTTP レスポンスコードについては、第 3 章の 3.4 節で詳しく説明しています。

### 5.8.1 Response Entities
- トランザクションでレスポンスボディが生成された場合、その内容が応答メッセージとともに返送されます。ボディがあった場合、応答メッセージには通常以下が含まれる。
  - 応答ボディのMIMEタイプを記述するContent-Typeヘッダー。
  - レスポンスボディのサイズを表す Content-Length ヘッダー
  - 実際のメッセージボディの内容 

### 5.8.2 MIME Typing
- レスポンスボディのMIMEタイプを決定するのは、ウェブサーバーの役目です。リソースにMIMEタイプを関連付けるためにサーバーを設定する方法はたくさんあります。

  - mime.types
    - Webサーバーは、ファイル名の拡張子を使って MIME タイプを示すことができます。Webサーバーは、各拡張子の MIME タイプを含むファイルをスキャンして、各リソースの MIME タイプを計算します。この拡張子ベースのタイプの関連付けは最も一般的なもので、図5-12に示されています。

  - Magic typing
    - Apache ウェブサーバは、各リソースのコンテンツをスキャンして、既知のパターンのテーブル（マジックファイルと呼ばれる）とコンテンツをパターンマッチさせて、各ファイルの MIME タイプを決定することができます。これには時間がかかりますが、特にファイル名に標準的な拡張子が付いていない場合には便利です。

  - Explicit typing
    - Webサーバーでは、ファイルの拡張子や内容にかかわらず、特定のファイルやディレクトリのコンテンツに強制的に MIME タイプを指定するように設定できます。

  - Type negotiation
    - Webサーバーの中には、リソースを複数のドキュメント形式で保存するように設定できるものがあります。この場合、Webサーバーは、ユーザーとのネゴシエーションプロセスによって、使用する「最適な」フォーマット（および関連する MIME タイプ）を決定するように設定できます。これについては第17章で説明します。

- また、ウェブサーバーは、特定のファイルとMIMEタイプを関連付けるように設定することもできます。

### 5.8.3 Redirection
- Webサーバーは、成功メッセージではなく、リダイレクトレスポンスを返すことがあります。Webサーバーは、リクエストを実行するためにブラウザを別の場所にリダイレクトすることができます。リダイレクションレスポンスは、3XXというリターンコードで示されます。Locationレスポンスヘッダには、コンテンツの新しい、または好ましい場所を示すURIが含まれています。リダイレクトは以下のような場合に有効です。

  - Permanently moved resources
    - リソースが新しい場所に移動されたり、名前が変更されたりして、新しいURLが与えられている場合です。ウェブサーバは、リソースの名前が変更されたことをクライアントに伝え、クライアントは新しい場所からリソースを取得する前に、ブックマークなどを更新することができます。この種のリダイレクトには、ステータスコード301 Moved Permanentlyが使用されます。

  - Temporarily moved resources
    - リソースが一時的に移動したり、名前が変更された場合、サーバーはクライアントを新しい場所にリダイレクトしたいと思うかもしれません。しかし、名前の変更は一時的なものなので、サーバーはクライアントが将来古いURLで戻ってくることを望んでおり、ブックマークを更新しないようにしています。このようなリダイレクトには、ステータスコード303「See Other」と307「Temporary Redirect」が使用されます。

  - URL augmentation - URLの拡張
    - サーバーはしばしばリダイレクトを使ってURLを書き換え、文脈を埋め込むことがあります。リクエストが到着すると、サーバーは埋め込まれた状態情報を含む新しいURLを生成し、ユーザーをこの新しいURLにリダイレクトします[7]。クライアントはリダイレクトに従い、リクエストを再発行しますが、その際には完全な拡張された状態のURLが含まれています。これは、トランザクション間で状態を維持するための便利な方法です。この種のリダイレクトには、ステータスコード303「See Other」および307「Temporary Redirect」が使用される。
    - [7] これらの拡張された状態のURLは、"fat URL "と呼ばれることもある。

  - Load balancing
    - 負荷の高いサーバーがリクエストを受けた場合、サーバーはクライアントを負荷の低いサーバーにリダイレクトすることができます。この種のリダイレクトには、ステータスコード303「See Other」および307「Temporary Redirect」が使用される。

  - Server affinity
    - Webサーバーは、特定のユーザーのローカル情報を持っている場合があります。サーバーは、クライアントに関する情報を持っているサーバーにクライアントをリダイレクトすることができます。このようなリダイレクトには、ステータスコード 303 See Other および 307 Temporary Redirect が使用されます。

  - Canonicalizing directory names - ディレクトリ名の正規化
    - クライアントが末尾にスラッシュのないディレクトリ名のURIを要求した場合、ほとんどのWebサーバーは、相対リンクが正しく動作するように、スラッシュを追加したURIにクライアントをリダイレクトします。

## 5.9 Step 6: Sending Responses
- ウェブサーバは、コネクションを介してデータを送信する際にも、受信する際と同様の問題に直面します。サーバーは、多くのクライアントとの間に多数の接続を持ち、あるものはアイドル状態、あるものはデータをサーバーに送信し、あるものはレスポンスデータをクライアントに返送します。
- サーバーは、接続状態を追跡し、持続的な接続を特別な注意を払って処理する必要があります。非持続的な接続では、メッセージがすべて送信された時点でサーバー側の接続を閉じることになっています。
- 持続的な接続では、接続が継続される可能性があります。その場合、サーバーはContent-Lengthヘッダーを正しく計算するために特別な注意を払う必要があり、そうしないとクライアントはいつレスポンスが終了するのかを知る方法がありません（第4章参照）。

## 5.10 Step 7: Logging
- 最後に、トランザクションが完了すると、ウェブサーバは実行されたトランザクションを記述したエントリをログファイルに記録します。ほとんどのウェブサーバーは、いくつかの設定可能な形式のログを提供しています。詳細は第21章を参照してください。

# Ch6 Proxies
- Webプロキシサーバーは、クライアントとサーバーの間に位置し、両者の間でHTTPメッセージをやりとりする「仲介役」です。本章では、HTTPプロキシサーバー、プロキシ機能の特別なサポート、およびプロキシサーバーを使用する際に見られる厄介な動作についてすべて説明します。この章では、以下のことを説明します。
  - HTTPプロキシについて、Webゲートウェイとの対比や、プロキシの導入方法を説明します。
  - プロキシが役立つ方法をいくつか紹介します。
  - 実際のネットワークにプロキシがどのように導入され、どのようにトラフィックがプロキシサーバーに誘導されるかを説明する。
  - プロキシを使用するようにブラウザを設定する方法を紹介します。
  - HTTP プロキシリクエストのデモンストレーションを行い、サーバーのリクエストとの違いや、プロキシがブラウザの動作を微妙に変化させる方法を説明する。
  - ViaヘッダとTRACEメソッドを使用して、プロキシサーバのチェーンを介してメッセージのパスを記録する方法を説明します。
  - プロキシベースのHTTPアクセスコントロールについて説明する。
  - クライアントとサーバの間でプロキシがどのように相互運用されるかを説明します。

## 6.1 Web Intermediaries
- Webプロキシサーバーは、クライアントの代わりにトランザクションを実行する仲介役です。Webプロキシがない場合、HTTPクライアントはHTTPサーバーと直接会話します。Webプロキシを使うと、クライアントに代わってプロキシサーバがサーバと通信します。クライアントは、プロキシサーバーの優れたサービスを利用して、トランザクションを完了します。
- HTTPプロキシサーバーは、ウェブサーバーであると同時にウェブクライアントでもあります。HTTPクライアントはプロキシにリクエストメッセージを送信するため、プロキシサーバーはウェブサーバーのようにリクエストと接続を適切に処理し、レスポンスを返さなければなりません。同時に、プロキシ自身もサーバーにリクエストを送信するので、プロキシも正しいHTTPクライアントのように振る舞い、リクエストを送信し、レスポンスを受信する必要があります（図6-1参照）。独自のHTTPプロキシを作成する場合は、HTTPクライアントとHTTPサーバーの両方のルールに注意深く従う必要があります。

### 6.1.1 Private and Shared Proxies
- プロキシサーバーには、1つのクライアント専用のものと、多数のクライアントで共有するものがあります。一人のクライアント専用のプロキシをプライベートプロキシと呼びます。多数のクライアントで共有するプロキシをパブリックプロキシと呼ぶ。

- パブリックプロキシ
  - ほとんどのプロキシは、パブリックプロキシ、つまり共有プロキシです。一元化されたプロキシの方が費用対効果が高く、管理もしやすいからです。また、キャッシングプロキシサーバーなどのプロキシアプリケーションは、より多くのユーザーが同じプロキシサーバーに集まることで、ユーザー間の共通のリクエストを利用できるようになり、より便利になります。

- プライベートプロキシ
  - 専用のプライベートプロキシはそれほど一般的ではありませんが、特にクライアントコンピュータ上で直接実行される場合には、その役割があります。一部のブラウザアシスタント製品や一部のISPサービスでは、ブラウザの機能拡張やパフォーマンスの向上、あるいは無料ISPサービスの広告のホストとして、ユーザーのPC上で小さなプロキシを直接実行している。

### 6.1.2 Proxies Versus Gateways
- 厳密に言えば、プロキシは同じプロトコルを使用する2つ以上のアプリケーションを接続し、ゲートウェイは異なるプロトコルを使用する2つ以上の相手を接続します。ゲートウェイは、クライアントとサーバーのプロトコルが異なっていても、クライアントがサーバーとのトランザクションを完了できるようにする「プロトコルコンバータ」の役割を果たします。
- 図6-2は、プロキシとゲートウェイの違いを示しています。

  - プロキシはクライアントとサーバーの両方にHTTPを話すので、図6-2aの仲介装置はHTTPプロキシである。
  - 図6-2bの仲介装置は、HTTPフロントエンドとPOPメールバックエンドを結びつけるので、HTTP/POPゲートウェイである。このゲートウェイは、Webトランザクションを適切なPOPトランザクションに変換し、ユーザーがHTTPで電子メールを読めるようにします。Yahoo! MailやMSN Hotmailなどのウェブベースの電子メールプログラムは、HTTP電子メールゲートウェイです。

- 実際には、プロキシとゲートウェイの違いは曖昧です。ブラウザとサーバは異なるバージョンのHTTPを実装しているため、プロキシはしばしばある程度のプロトコル変換を行います。また、市販のプロキシサーバは、SSLセキュリティプロトコル、SOCKSファイアウォール、FTPアクセス、Webベースのアプリケーションをサポートするゲートウェイ機能を実装しています。ゲートウェイについては第8章で詳しく説明します。

## 6.2 Why Use Proxies?
- プロキシサーバーには、さまざまな便利な機能があります。セキュリティの向上、パフォーマンスの向上、コストの削減などが可能です。また、プロキシサーバは、通過するすべてのHTTPトラフィックを見たり触ったりすることができるので、プロキシはトラフィックを監視したり変更したりして、多くの有用な付加価値のあるウェブサービスを実装することができます。ここでは、プロキシの利用方法のほんの一例をご紹介します。
- Child filter (Figure 6-3)
  - 小学校では、フィルタリングプロキシを使用して、アダルトコンテンツへのアクセスをブロックする一方で、教育用サイトへのアクセスは制限しないようにしている。図6-3に示すように、プロキシは、教育用コンテンツへの無制限のアクセスを許可するが、子供に不適切なサイトへのアクセスを強制的に拒否することができる[1]。
  - [1] 不快なコンテンツを特定してアクセスを制限するために、いくつかの企業や非営利団体がフィルタリングソフトウェアを提供し、「ブラックリスト」を管理している。

- Document access controller (Figure 6-4)
  - プロキシサーバーは、大規模なウェブサーバーやウェブリソースに対して統一的なアクセスコントロール戦略を実施し、動作記録を作成するために使用することができます。これは、大企業やその他の分散した官僚組織で有効です。すべてのアクセス制御は、集中管理されたプロキシサーバで設定することができ、異なる組織によって管理されている、メーカーやモデルの異なる多数のウェブサーバでアクセス制御を頻繁に更新する必要はありません[2]。
  - [2] 洗練されたユーザが故意に制御プロキシを迂回することを防ぐために、ウェブ・サーバはプロキシ・サーバからの要求のみを受け入れるように静的に構成することができる。
  - 図6-4は，集中型のアクセス制御プロキシである。
    - クライアント1にサーバAからのニュースページへのアクセスを無制限に許可する
    - クライアント2にインターネットコンテンツへの無制限のアクセスを許可する。
    - サーバBへのアクセスを許可する前に、クライアント3からパスワードを要求する。

- Security firewall (Figure 6-5)
  - ネットワーク・セキュリティ・エンジニアは、セキュリティを強化するためにプロキシ・サーバを使用することが多い。プロキシ・サーバは、アプリケーション・レベルのプロトコルが組織に出入りするのを、ネットワーク上の安全な一点で制限します。また、ウイルスを排除するウェブや電子メールのプロキシのように、トラフィックを精査するためのフックを提供することもできます（図6-5）。

- Web cache (Figure 6-6)
  - プロキシ・キャッシュは、人気のあるドキュメントのローカル・コピーを維持し、必要に応じてそれらを提供することで、時間とコストのかかるインターネット通信を削減します。
  - 図6-6では、クライアント1と2は近くのウェブ・キャッシュからオブジェクトAにアクセスし、クライアント3と4はオリジン・サーバーからドキュメントにアクセスする。

- Surrogate (Figure 6-7)
  - プロキシは、Webサーバーを装うことができます。サロゲートやリバースプロキシと呼ばれるプロキシは、実際のWebサーバーのリクエストを受信しますが、Webサーバーとは異なり、要求されたコンテンツを見つけるために他のサーバーとの通信を開始することがあります。
  - サロゲートは、一般的なコンテンツを扱う低速のウェブサーバーのパフォーマンスを向上させるために使用することができます。この構成では、サロゲートはしばしばサーバーアクセラレータと呼ばれます（図6-7）。サロゲートは、コンテンツ・ルーティング機能と組み合わせて、オンデマンドで複製されたコンテンツの分散型ネットワークを構築するためにも使用できます。

- Content router (Figure 6-8)
  - プロキシサーバは、インターネットのトラフィック状況やコンテンツの種類に応じて、リクエストを特定のWebサーバに転送する「コンテンツルータ」として機能します。
  - コンテンツルーターは、さまざまなサービスレベルの提供にも使用できます。例えば、コンテンツルータは、ユーザやコンテンツプロバイダがより高いパフォーマンスを求めている場合には、リクエストを近くのレプリカキャッシュに転送したり（図6-8）、ユーザがフィルタリングサービスに申し込んでいる場合には、HTTPリクエストをフィルタリングプロキシに通したりすることができます。アダプティブ・コンテンツ・ルーティング・プロキシを使って、多くの興味深いサービスを構築することができます。

- Transcoder (Figure 6-9)
  - プロキシサーバーは、クライアントに配信する前に、コンテンツのボディフォーマットを変更することができる。このようなデータ表現間の透過的な変換をトランスコードと呼ぶ[3]。
  - [3]「トランスコード」と「トランスレーション」を区別して、トランスコードはデータのエンコーディングの比較的単純な変換（可逆圧縮など）、トランスレーションはデータの再フォーマットやセマンティックな変更など、より重要なものと定義する人もいる。本書では、トランスコーディングという用語を、コンテンツのあらゆる仲介ベースの変更を意味するものとして使用しています。
  - トランスコーディングプロキシは、GIF画像をJPEG画像に変換してサイズを小さくすることができる。また、テレビで見やすいように画像を縮小したり、色の濃さを減らしたりすることもできる。同様に、テキストファイルも圧縮され、インターネット対応のポケベルやスマートフォン用にWebページの小さなテキスト要約を生成することができます。さらに、プロキシがその場でドキュメントを外国語に変換することも可能です。
  - 図6-9は、英語のテキストをスペイン語のテキストに変換したり、HTMLページを携帯電話の小さな画面に表示できるようなシンプルなテキストに再フォーマットするトランスコーディングプロキシを示している。

- Anonymizer (Figure 6-10)
  - アノニマイザープロキシは、HTTPメッセージから識別可能な特性（クライアントのIPアドレス、Fromヘッダー、Refererヘッダー、Cookie、URIセッションIDなど）を積極的に取り除くことで、プライバシーと匿名性を高めます[4]。
  - [4] ただし、識別情報が除去されるため、ユーザーのブラウジング体験の質が低下したり、一部のWebサイトが正常に機能しない場合があります。
  - 図6-10では、アノニマイザープロキシはプライバシーを高めるためにユーザのメッセージに以下の変更を加えている。プライバシーを向上させる。
    - User-AgentヘッダからユーザのコンピュータおよびOSタイプを削除する。
    - ユーザーの電子メールアドレスを保護するために、Fromヘッダーが削除される。
    - Refererヘッダを削除することで、ユーザが訪問した他のサイトを見えにくくしています。
    - Cookieヘッダを削除することで、プロファイリングやIDデータを排除しています。

## 6.3 Where Do Proxies Go?
- ここでは、プロキシがネットワーク・アーキテクチャに導入されたときの位置について説明します。以下の内容を説明します。
  - プロキシをネットワークに配置する方法
  - プロキシを階層化する方法
  - そもそもトラフィックがプロキシサーバーに誘導される仕組み 

### 6.3.1 Proxy Server Deployment
- プロキシは用途に応じて様々な場所に設置することができます。図6-11は、プロキシサーバーを配置する方法をいくつか示しています。

- Egress proxy (Figure 6-11a)
  - ローカルネットワークの出口にプロキシを貼り付けて、ローカルネットワークとインターネットの間のトラフィックフローを制御することができます。企業では、社外の悪質なハッカーに対するファイアウォールの保護や、インターネットトラフィックの帯域料金の削減とパフォーマンスの向上のために、エグレスプロキシを使用することがあります。小学校では、早熟な生徒が不適切なコンテンツを閲覧するのを防ぐために、フィルタリング用のイグレスプロキシを使用することがあります。

- Access (ingress) proxy (Figure 6-11b)
  - プロキシはISPのアクセスポイントに設置されることが多く、顧客からのリクエストを集約して処理する。ISPは、キャッシングプロキシを使用して人気のある文書のコピーを保存し、ユーザー（特に高速接続のユーザー）のダウンロード速度を向上させ、インターネット帯域幅のコストを削減する。

- Surrogates (Figure 6-11c)
  - プロキシは、サロゲート（一般的にリバースプロキシとも呼ばれる）としてネットワークの端、Webサーバの前に配置されることが多く、Webサーバに向けられたすべてのリクエストを処理し、必要な場合にのみWebサーバにリソースを要求することができます。サロゲートは、ウェブサーバーにセキュリティ機能を追加したり、高速なウェブサーバーのキャッシュを低速なウェブサーバーの前に置くことでパフォーマンスを向上させることができます。サロゲートは通常、ウェブサーバーの名前とIPアドレスを直接想定しているため、すべてのリクエストはサーバーではなくプロキシに送られます。

- Network exchange proxy (Figure 6-11d)
  - 十分な馬力があれば、プロキシはインターネット上のネットワーク間のピアリング交換ポイントに設置され、キャッシュによるインターネットジャンクションでの混雑の緩和や、トラフィックフローの監視を行うことができる[5]。
  - [5] コアプロキシは、インターネットの帯域幅が非常に高価な場所（特にヨーロッパ）でよく導入されています。また、イギリスなどの一部の国では、国家安全保障上の懸念からインターネット・トラフィックを監視するために、プロキシの導入を検討している。

### 6.3.2 Proxy Hierarchies
- プロキシは、プロキシ階層と呼ばれるチェーンでカスケード接続できます。プロキシ階層では、図6-12に示すように、メッセージはプロキシからプロキシへと渡され、最終的にオリジン・サーバーに到達するまで（その後、プロキシを経由してクライアントに戻されるまで）、メッセージが渡される。
- プロキシ階層内のプロキシサーバには、親と子の関係が割り当てられています。次の受信プロキシ(サーバに近い方)を親と呼び、次の送信プロキシ(クライアントに近い方)を子と呼ぶ。図6-12では、プロキシ1はプロキシ2の子プロキシである。同様に、プロキシ2はプロキシ3の子プロキシであり、プロキシ3はプロキシ2の親プロキシである。

```
Fig 6-12. ３レベルのプロキシ階層
Client <--> Proxy1 <--> Proxy2 <--> Proxy3 <--> Origin server
```

#### 6.3.2.1 Proxy hierarchy content routing
- 図 6-12 のプロキシ階層は静的で、プロキシ 1 は常にプロキシ 2 にメッセージを転送し、プロキシ 2 は常にプロキシ 3 にメッセージを転送します。しかし、階層は静的である必要はありません。プロキシ・サーバは、多くの要因に基づいて、変化するプロキシ・サーバとオリジン・サーバのセットにメッセージを転送することができます。
- 例えば、図6-13では、アクセスプロキシは異なる状況下で親プロキシやオリジンサーバにルーティングする。

  - 要求されたオブジェクトが、コンテンツ配信にお金を払っているウェブサーバに属している場合、プロキシはリクエストを近くのキャッシュサーバにルーティングし、キャッシュされたオブジェクトを返すか、利用できない場合にはそれを取り出すことができる。
  - リクエストが特定の種類の画像の場合、アクセスプロキシはリクエストを専用の圧縮プロキシに転送し、画像を取得してから圧縮することで、遅いモデムでもクライアントへのダウンロードを高速化することができます。

- ここでは、動的な親の選択の他の例をいくつか紹介します。

- 負荷分散
  - 子プロキシは、親プロキシの現在の作業負荷レベルに基づいて親プロキシを選択し、負荷を分散することができる。

- 地理的近接性のあるルーティング
  - 子プロキシがオリジンサーバの地理的な地域を担当する親を選択することがある。

- プロトコル/タイプルーティング
  - 子プロキシは、URIに基づいて異なる親やオリジンサーバにルーティングすることがある。URIの種類によっては、特別なプロトコルを処理するために、特別なプロキシサーバを経由してリクエストを転送することがあります。

- サブスクリプションベースのルーティング
  - パブリッシャーが高性能なサービスのために追加料金を支払っている場合、そのURIはパフォーマンスを向上させるために大規模なキャッシュや圧縮エンジンにルーティングされることがあります。

- 動的なペアレントルーティングロジックは、設定ファイル、スクリプト言語、動的実行可能なプラグインなど、製品によって実装方法が異なります。

### 6.3.3 How Proxies Get Traffic
- 通常、クライアントはウェブサーバーと直接対話するため、そもそもHTTPトラフィックがどのようにしてプロキシにたどり着くのかを説明する必要があります。クライアントのトラフィックがプロキシに到達するための一般的な方法は4つあります。

- クライアントを変更する
  - NetscapeやMicrosoftのブラウザをはじめとする多くのWebクライアントは、手動および自動のプロキシ設定をサポートしています。クライアントがプロキシサーバーを使用するように設定されている場合、クライアントはHTTPリクエストをオリジンサーバーにではなく、プロキシに直接かつ意図的に送信します（図6-14a）。

- ネットワークの変更
  - ネットワーク・インフラストラクチャが、クライアントの認識や参加なしにウェブ・トラフィックを傍受し、プロキシに誘導する手法がいくつかあります。この傍受は通常、クライアントに気づかれないようにHTTPトラフィックを監視し、それを傍受し、トラフィックをプロキシに振り分けるスイッチングおよびルーティング装置に依存しています（図6-14b）。これを「インターセプティングプロキシ」と呼びます[6]。
  - [6] 傍受プロキシは、その存在を意識せずに接続することから、一般に「トランスペアレントプロキシ」と呼ばれています。HTTP仕様では、セマンティックな動作を変更しない機能を示すために、すでに「トランスペアレンシー」という用語が使われているため、標準化団体では、トラフィックの捕捉に「インターセプト」という用語を使うことを提案している。ここではこの命名法を採用する。

- DNS名前空間の変更
  - Webサーバの前に置かれたプロキシサーバであるサロゲートは、Webサーバの名前とIPアドレスを直接想定しているため、すべてのリクエストはサーバではなくサロゲートに送られます（図 6-14c). これを実現するには、DNSネーミングテーブルを手動で編集するか、適切なプロキシまたはサーバーをオンデマンドで計算する特別なダイナミックDNSサーバーを使用します。一部のインストールでは、実際のサーバーのIPアドレスと名前が変更され、サロゲートには以前のアドレスと名前が与えられます。

- Webサーバーの変更 
  - ウェブサーバの中には、クライアントにHTTPリダイレクションコマンド（レスポンスコード305）を送り返すことで、クライアントのリクエストをプロキシにリダイレクトするように設定できるものもあります。リダイレクトを受け取ったクライアントは、プロキシとの取引を行います（図6-14d）。

- 次の章では、プロキシにトラフィックを送信するためのクライアントの設定方法を説明します。第20章では、プロキシサーバーにトラフィックをリダイレクトするためのネットワーク、DNS、サーバーの設定方法について説明します。

## 6.4 Client Proxy Settings
- 最近のウェブブラウザでは、プロキシの使用を設定することができます。実際、多くのブラウザでは、以下のような複数の方法でプロキシを設定することができます。
  - Manual configuration
  - Browser preconfiguration
    - ブラウザのベンダーやディストリビューターは、顧客に提供する前に、ブラウザ（またはその他のWebクライアント）のプロキシ設定を手動で事前に行っています。
  - Proxy auto-configuration (PAC)
    - クライアントは、JavaScriptのプロキシ自動設定（PAC）ファイルのURIを提供し、JavaScriptファイルを取得して実行することで、プロキシを使用するかどうか、使用する場合はどのプロキシサーバーを使用するかを決定します。
  - WPAD proxy discovery
    - 一部のブラウザはWPAD（Web Proxy Autodiscovery Protocol）をサポートしており、ブラウザが自動設定ファイルをダウンロードできる「設定サーバー」を自動的に検出する[7]。

### 6.4.1 Client Proxy Configuration: Manual
- 多くのWebクライアントでは、プロキシを手動で設定することができます。Netscape NavigatorもMicrosoft Internet Explorerも、プロキシの設定を便利にサポートしています。
- プロキシのホストとポートを指定することで設定する。

### 6.4.2 Client Proxy Configuration: PAC Files
- 手動でのプロキシ設定は簡単ですが、柔軟性に欠けます。すべてのコンテンツに対して1つのプロキシサーバーしか指定できず、フェイルオーバーにも対応していません。また、手動によるプロキシ設定は、大規模な組織では管理上の問題を引き起こします。設定されたブラウザの数が多い場合、変更が必要になったときにすべてのブラウザを再設定することは困難または不可能です。
- PAC（Proxy Auto-Configuration）ファイルは、プロキシ設定をその場で計算する小さなJavaScriptプログラムなので、プロキシ設定のためのよりダイナミックなソリューションです。ドキュメントにアクセスするたびに、JavaScriptの関数が適切なプロキシサーバーを選択します。
- PACファイルを使用するには、JavaScriptのPACファイルのURIをブラウザに設定します（設定は手動設定と似ていますが、「自動設定」ボックスにURIを指定します）。ブラウザはこのURIからPACファイルを取得し、JavaScriptのロジックを使って各アクセスに適切なプロキシサーバーを計算します。PACファイルは通常、接尾辞が.pacで、MIMEタイプが "application/x-ns-proxy-autoconfig "となっています。各PACファイルは、URIへのアクセスに使用する適切なプロキシサーバーを計算するFindProxyForURL(url,host)という関数を定義する必要があります。この関数の戻り値は，表6-1に示す値のいずれかとなる。
  - DIRECT
  - PROXY host:port
  - SOCKS host:port
- PACファイルの詳細はChapter20を参照。

### 6.4.3 Client Proxy Configuration: WPAD
- ブラウザを設定するもうひとつの仕組みとして、WPAD（Web Proxy Autodiscovery Protocol）があります。WPADは、発見メカニズムのエスカレーション戦略を用いて、ブラウザに適切なPACファイルを自動的に見つけるアルゴリズムです。WPADプロトコルを実装したクライアントは、以下のことを行います。

  - WPADを使ってPACのURIを見つける。
  - そのURIからPACファイルを取得する。
  - PACファイルを実行してプロキシサーバを決定する。
  - リクエストに対してプロキシサーバーを使用する。

- WPADは、適切なPACファイルを決定するために、一連のリソース発見技術を使用する。すべての組織がすべての技術を使用できるわけではないので、複数の発見技術が使用される。WPADは、成功するまで各技術を1つずつ試みる。現在のWPADの仕様では、以下の技術が順に定義されています。

  - ダイナミックホストディスカバリープロトコル（DHCP）
  - サービスロケーションプロトコル(SLP)
  - DNS well-known hostnames
  - DNSのSRVレコード
  - TXTレコード内のDNSサービスURI

- 詳細については、第20章をご参照ください。

## 6.5 Tricky Things About Proxy Requests
- このセクションでは、プロキシサーバーのリクエストについて、以下のような厄介で誤解されやすい点を説明します。

  - プロキシリクエストのURIがサーバーリクエストとどのように異なるか
  - プロキシのインターセプトやリバースプロキシによってサーバのホスト情報がどのように不明瞭になるか
  - URIの変更に関するルール
  - プロキシがブラウザの巧妙なURI自動補完機能やホスト名拡張機能に与える影響

### 6.5.1 Proxy URIs Differ from Server URIs
- WebサーバとWebプロキシのメッセージは、1つの例外を除いて同じ構文です。クライアントがプロキシではなくサーバにリクエストを送信する場合、HTTPリクエストメッセージ内のURIが異なります。クライアントがウェブサーバにリクエストを送信する場合、リクエスト行には、次の例に示すように、URIの一部（スキーム、ホスト、ポートを含まない）のみが含まれます。

```
GET /index.html HTTP/1.0
User-Agent: SuperBrowserv1.3
```

- しかし、クライアントがプロキシにリクエストを送信する場合、リクエストラインには完全なURIが含まれます。例えば、次のようになります。

```
GET http://www.marys-antiques.com/index.html HTTP/1.0
User-Agent: SuperBrowser v1.3 
```

- なぜ、プロキシ用とサーバー用の2つの異なるリクエストフォーマットがあるのですか？オリジナルのHTTPデザインでは、クライアントは1つのサーバーに直接話しかけていました。バーチャルホストは存在せず、プロキシについても用意されていませんでした。単一のサーバは自分のホスト名とポートを知っているため、冗長な情報を送信しないように、クライアントはスキームとホスト(およびポート)を除いた部分的なURIを送信しました。
- プロキシが登場すると、この部分的なURIが問題になりました。プロキシは、サーバへの独自の接続を確立するために、宛先サーバの名前を知る必要がありました。また、プロキシベースのゲートウェイは、FTPリソースやその他のスキームに接続するために、URIのスキームを必要としました。HTTP/1.0は、プロキシのリクエストに完全なURIを要求することで問題を解決しましたが、サーバーのリクエストには部分的なURIを保持していました（完全なURIをサポートするためにすべてのサーバーを変更するには、すでに多くのサーバーが配備されていました）[8]。
  - [8] HTTP/1.1では、サーバーはプロキシリクエストとサーバーリクエストの両方で完全なURIを処理することが要求されていますが、実際には、多くのデプロイされたサーバーはまだ部分的なURIしか受け付けません。
- そのため、部分的なURIをサーバーに、完全なURIをプロキシに送る必要があります。クライアントのプロキシ設定が明示的に設定されている場合、クライアントはどのようなタイプのリクエストを発行すべきかを知っています。

  - クライアントがプロキシを使用するように設定されていない場合は、部分URIを送信します（図6-15a）。
  - クライアントがプロキシを使用するように設定されている場合は、完全なURIを送信します（図6-15b）。

### 6.5.2 The Same Problem with Virtual Hosting
- プロキシの「scheme/host/port が見つからない」問題は、仮想ホスト型のウェブサーバーが直面する問題と同じです。仮想ホスト型ウェブサーバは、多くのウェブサイトで同じ物理的ウェブサーバを共有しています。部分的なURI /index.htmlに対するリクエストが来ると、仮想ホスト型Webサーバは目的のWebサイトのホスト名を知る必要があります(詳細はセクション5.7.1.1とセクション18.2を参照)。
- これらの問題は類似しているにもかかわらず、異なる方法で解決されました。
  - 明示的なプロキシは、リクエストメッセージに完全なURIを要求することで問題を解決しています。
  - 仮想ホストされているウェブサーバーは、ホストとポートの情報を伝えるためにHostヘッダーを必要とします。

### 6.5.3 Intercepting Proxies Get Partial URIs
- クライアントがHTTPを適切に実装している限り、クライアントは明示的に設定されたプロキシへのリクエストで完全なURIを送信します。これで問題の一部は解決しましたが、プロキシの中にはクライアントからは見えないものもあるため、クライアントがプロキシと話していることを常に知ることはできません。また、クライアントがプロキシを使用するように設定されていなくても、クライアントのトラフィックがサロゲートプロキシやインターセプトプロキシを経由する場合があります。どちらの場合も、クライアントはWebサーバーと通信していると思い込み、完全なURIを送信しません。
  - サロゲートとは、前述したように、通常はホスト名やIPアドレスを仮定してオリジンサーバーの代わりを務めるプロキシサーバーのことです。サロゲートはウェブサーバーのリクエストを受け取り、キャッシュされたレスポンスを提供したり、実際のサーバーへのプロキシリクエストを提供したりします。クライアントはサロゲートをウェブサーバと区別できないため、部分的なURIを送信します（図6-15c）。
  - 傍受プロキシとは、ネットワークの流れの中にあるプロキシサーバで、クライアントからサーバへのトラフィックをハイジャックし、キャッシュされた応答を提供するか、プロキシするものである。インターセプティングプロキシは、クライアントからサーバへのトラフィックをハイジャックするため、Webサーバに送信されるURIを部分的に受信することになる（図6-15d）[9]。
  - [9] 傍受プロキシも、状況によってはクライアントからプロキシへのトラフィックを傍受するかもしれません。その場合、傍受プロキシは完全なURIを受け取り、それを処理する必要があるかもしれません。明示的なプロキシは通常、HTTPで使用されるポートとは異なるポート(通常は80ではなく8080)で通信し、傍受するプロキシは通常、ポート80のみを傍受するので、このようなことはあまり起こらない。

### 6.5.4 Proxies Can Handle Both Proxy and Server Requests
- トラフィックがプロキシサーバにリダイレクトされる方法は様々なので、汎用プロキシサーバはリクエストメッセージ中の完全なURIと部分的なURIの両方をサポートするべきである。プロキシは、明示的なプロキシ要求であれば完全なURIを使用し、Webサーバの要求であれば部分URIと仮想Hostヘッダを使用すべきである。
- 完全なURIと部分的なURIを使用するためのルールは以下の通りです。

  - 完全なURIが提供された場合，プロキシはそれを使用すべきである。
  - 部分的なURIが提供され、Hostヘッダーが存在する場合、オリジンサーバー名とポート番号を決定するためにHostヘッダーが使用されるべきである。
  - 部分的なURIが提供され、Hostヘッダーが存在しない場合、オリジンサーバーは何らかの他の方法で決定される必要がある。
    - プロキシがオリジンサーバーの代わりに立つサロゲートである場合、 プロキシは実際のサーバーのアドレスとポート番号で設定できる。
    - トラフィックが傍受され、傍受者がオリジナルのIPアドレスとポートを利用可能にしている場合、プロキシは傍受技術から得たIPアドレスとポート番号を使用することができる(第20章参照)。
    - 他のすべてが失敗した場合、プロキシはオリジンサーバーを決定するのに十分な情報を持っていないので、エラーメッセージを返さなければならない(多くの場合、ユーザーにHostヘッダーをサポートする最新のブラウザにアップグレードするよう提案する)[10] 。
    - [10] これは気軽に行うべきではありません。ユーザーは、今まで受けたことのない不可解なエラーページを受け取ることになります。

### 6.5.5 In-Flight URI Modification
- プロキシサーバは、メッセージを転送する際にリクエストURIを変更することに十分注意する必要があります。URIのわずかな変更は、たとえそれが無害に見えたとしても、下流のサーバとの相互運用性の問題を引き起こす可能性があります。
- 一般的に、プロキシサーバは可能な限り寛容であるように努めるべきです。なぜなら、これまで機能していたサービスが大きく破壊される可能性があるからです。
- 特に、HTTP仕様では、一般的な傍受プロキシがURIを転送する際にURIの絶対パス部分を書き換えることを禁止しています。唯一の例外は、空のパスを「/」で置き換えることができることです。

### 6.5.6 URI Client Auto-Expansion and Hostname Resolution
- ブラウザは、プロキシが存在するかどうかによって、リクエストURIの解決方法が異なります。プロキシがない場合、ブラウザは入力されたURIを受け取り、対応するIPアドレスを探そうとします。ホスト名が見つかれば、ブラウザは接続に成功するまで対応するIPアドレスを探します。
- しかし、ホストが見つからない場合、多くのブラウザは、ホストの「短縮形」の略語を入力した場合に備えて、ホスト名を自動的に「拡張」しようとします（第2.3.2節に戻って参照してください）[11]。
- [11] ほとんどのブラウザでは、「yahoo」と入力すると自動的に「www.yahoo.com」と展開されます。同様に、ブラウザは "http://"というプレフィックスを省略したり、不足していれば挿入したりすることができます。
  - 多くのブラウザは、一般的なウェブサイト名の中間部分を入力した場合に備えて、「www.」のプレフィックスと「.com」のサフィックスを追加しようとします（例えば、「www.yahoo.com」の代わりに「yahoo」と入力させる場合など）。
  - 一部のブラウザでは、解決できなかったURIをサードパーティのサイトに渡して、スペルミスを修正したり、意図していたかもしれないURIを提案しようとするものもあります。
  - さらに、ほとんどのシステムのDNS設定では、ホスト名のプレフィックスだけを入力すると、DNSが自動的にドメインを検索します。ドメイン「oreilly.com」にいるときに、ホスト名「host7」と入力すると、DNSは自動的に「host7.oreilly.com」と一致させようとします。これは完全で有効なホスト名ではありません。

### 6.5.7 URI Resolution Without a Proxy
- 図6-16は、プロキシを使わずにブラウザのホスト名を自動展開した例である。ステップ2a～3cでは 有効なホスト名が見つかるまで、ブラウザはホスト名のバリエーションを検索します。
  - oreillyと入力した場合、ホストoreillyでDNS名前解決しようとして失敗し、その後ブラウザは自動拡張でoreillyをwww.oreilly.comに変換し、これでDNS名前解決を試みて成功し、通信を開始する。

### 6.5.8 URI Resolution with an Explicit Proxy
- 明示的なプロキシを使用すると、ユーザの URI がプロキシに直接渡されるため、ブラウザはこれらの便宜的な展開を行わなくなります。図 6-17 に示すように、明示的なプロキシがある場合、ブラウザは部分的なホスト名を自動展開しません。その結果、ユーザがブラウザのロケーションウィンドウに「oreilly」と入力すると、プロキシには「http://oreilly/」が送られる（ブラウザはデフォルトのスキームとパスを追加するが、ホスト名は入力したままにする）。
- このため、プロキシの中には、「www...com」の自動展開やローカルドメインのサフィックスの追加など、ブラウザの便利なサービスをできるだけ真似しようとするものがあります[12]。

### 6.5.9 URI Resolution with an Intercepting Proxy
- ホスト名の解決は、目に見えない傍受プロキシの場合は少し異なります。というのも、クライアントにとってはプロキシがないからです。挙動はサーバの場合とほぼ同じで、DNSが成功するまでブラウザはホスト名を自動展開します。しかし、図6-18が示すように、サーバへの接続時に大きな違いが生じます。
- 傍受プロキシは、ブラウザが提供するのと同等のフォールト・トレランスを提供するために、Hostヘッダ内のホスト名を解決するか、IPアドレスのDNS逆引きを行うかして、他のIPアドレスを試す必要がある。ブラウザが明示的プロキシを使用する設定の場合、プロキシにフォールト・トレランスを頼ることになるので、傍受プロキシと明示的プロキシの両方が、死んだサーバーへのDNS解決に関するフォールト・トレランスをサポートすることが重要である。

## 6.6 Tracing Messages
- 今日では、Webリクエストがクライアントからサーバーに届くまでに、2つ以上のプロキシを連鎖的に経由することも珍しくありません（図6-19）。今日、ウェブリクエストのかなりの割合がプロキシを経由しています。
- プロキシが普及するにつれ、異なるスイッチやルーターを経由したIPパケットの流れを追跡することが重要であるのと同様に、プロキシを経由したメッセージの流れを追跡し、問題を検出する能力が必要となります。

### 6.6.1 The Via Header
- Via ヘッダーフィールドには，メッセージが通過する各中間ノード（プロキシやゲートウェイ）に関する情報がリストアップされています。メッセージが他のノードを経由するたびに、その中間ノードをViaリストの最後に追加する必要があります。
- Viaヘッダーフィールドは、メッセージの転送を追跡し、メッセージのループを診断し、リクエス ト/レスポンスチェーンに沿ったすべての送信者のプロトコル機能を特定するために使用される（図 6-20）。

#### 6.6.1.1 Via syntax
- Viaヘッダーフィールドは、コンマで区切られたウェイポイントのリストを含む。各ウェイポイントは、個々のプロキシサーバまたはゲートウェイのホップを表し、その中間ノードのプロトコルとアドレスに関する情報を含みます。
  - Protocol name
  - Protocol version
  - Node name
  - Node comment

#### 6.6.1.2 Via request and response paths
- リクエストとレスポンスは通常同一のTCPコネクション上を通る。そのため、レスポンスのViaヘッダーは、ほぼ常にリクエストのViaヘッダーを反転したものになる。

#### 6.6.1.3 Via and gateways]
- プロキシはゲートウェイの機能を提供する場合があり、その場合HTTP以外のプロトコル変換についてもViaヘッダーに記録される。クライアントはレスポンスのViaヘッダーを見て、プロキシチェーンに沿ったプロトコル機能と変換について気づくことができる。

#### 6.6.1.4 The Server and Via headers
- サーバーは、サーバーレスポンスヘッダフィールドにオリジンサーバーで使われるソフトウェアを記述する。
- 応答メッセージがプロキシ経由で転送される場合は、プロキシが Server ヘッダを変更しないようにしてください。Serverヘッダーはオリジンサーバーのためのものです。代わりに、プロキシは Via エントリを追加する必要があります。

#### 6.6.1.5 Privacy and security implications of Via
- Via文字列に正確なホスト名を入れたくない場合もあります。一般的に、この動作が明示的に有効になっていない限り、プロキシサーバがネットワークのファイアウォールの一部である場合、ファイアウォールの背後にあるホストの名前とポートを転送すべきではありません。これは、ファイアウォールの背後にあるネットワークアーキテクチャの知識が悪意のある当事者に利用される可能性があるからです[14]。
- Viaノード名転送が有効でない場合、セキュリティ境界の一部であるプロキシは、ホスト名をそのホストの適切な偽名に置き換える必要があります。しかし、一般的には、プロキシは、実名が不明瞭であっても、各プロキシサーバのViaウェイポイントエントリを保持するようにすべきである。
- 内部ネットワークアーキテクチャのデザインやトポロジーを不明瞭に することに非常に強いプライバシー要求を持つ組織の場合、プロキ シは(同一のreceived-protocol値を持つ)順番に並んだViaウェイポ イントエントリを単一の結合されたエントリにまとめることができる。例えば、以下のようにである。

```
Via: 1.0 foo, 1.1 devirus.company.com, 1.1 accesslogger.company.com
->
Via: 1.0 foo, 1.1 concealed-stuff 
```

- 同じ組織の管理下にあり、ホストがすでに偽名に置き換えられている場合を除き、複数のエントリを結合しないでください。また、received-protocolの値が異なるエントリーを結合してはいけません。

### 6.6.2 The TRACE Method
- プロキシネットワークを簡単に診断するためには、HTTPプロキシネットワークを介してホップごとに転送されるメッセージがどのように変化するかを便利に観察する方法が必要です。
- HTTP/1.1 の TRACE メソッドは、プロキシの連鎖を通してリクエストメッセージを追跡し、メッセージがどのプロキシを通過し、各プロキシがリクエストメッセージをどのように変更するかを観察することができます。TRACEはプロキシの流れをデバッグするのに非常に便利です[15]。
  - [15] 残念ながら、これはまだ広く実装されていません。
- TRACEリクエストが宛先サーバに到達すると[16]、リクエストメッセージ全体がHTTPレスポンスのボディにまとめられて送信者に返信されます（図6-23参照）。TRACEレスポンスが到着すると、クライアントは、サーバが受信した正確なメッセージと、そのメッセージが通過したプロキシのリスト（Viaヘッダ内）を確認することができます。TRACEの応答は、Content-Typeがmessage/httpで、ステータスが200 OKです。
  - [16] 最終的な受信者は、オリジンサーバーか、リクエストでMax-Forwards値0を受け取った最初のプロキシまたはゲートウェイのいずれかである。

#### 6.6.2.1 Max-Forwards
- 通常、TRACEメッセージは、介在するプロキシの数に関係なく、デスティネーションサーバまで全行程を移動します。Max-Forwardsヘッダを使用して、TRACEとOPTIONSリクエストのプロキシホップ数を制限することができます。これは、無限ループでメッセージを転送するプロキシのチェーンをテストしたり、チェーンの途中にある特定のプロキシサーバーの影響をチェックするのに便利です。MaxForwardsはまた、OPTIONSメッセージの転送を制限します（セクション6.8参照）。
- Max-Forwardsリクエストヘッダーフィールドは、このリクエストメッセージ が転送される可能性のある残り回数を示す一つの整数を含む(図6-24)。Max-Forwardsの値がゼロの場合(MaxForwards: 0)、受信者がオリジンサーバーでなくても、TRACEメッセージをそれ以上転送せずにクライアントに向けて反映させなければならない。
- 受信したMax-Forwardsの値がゼロより大きい場合、転送されたメッセージには、値を1つ減らした更新されたMax-Forwardsフィールドが含まれていなければなりません。すべてのプロキシとゲートウェイはMax-Forwardsをサポートする必要があります。Max-Forwardsを使って、プロキシチェーンのどのホップでもリクエストを見ることができます。

## 6.7 Proxy Authentication
- プロキシは、アクセス制御装置として機能します。HTTPはプロキシ認証と呼ばれるメカニズムを定義しており、ユーザーがプロキシに有効なアクセス許可の認証情報を提供するまで、コンテンツへのリクエストをブロックします。
  - 制限されたコンテンツへのリクエストがプロキシサーバーに到着すると、プロキシサーバーはアクセス資格を要求する407 Proxy Authorization Requiredステータスコードを返し、その資格を提供する方法を記述したProxy-Authenticateヘッダーフィールドを添付することができる(図6-25b)。
  - 407応答を受信したクライアントは、ローカルデータベースから、またはユーザにプロンプトを表示して、必要な資格情報を収集しようとする。
  - クレデンシャルが取得されると、クライアントはProxy-Authorizationヘッダーフィールドに必要なクレデンシャルを提供してリクエストを再送する。
  - クレデンシャルが有効であれば、プロキシはオリジナルのリクエストをチェーンに沿って渡し(図6-25c)、そうでなければ別の407応答が送られる。
- 一般に、プロキシ認証は、複数のプロキシが連鎖し、それぞれが認証に参加する場合には、うまく機能しません。認証情報をプロキシチェーン内の特定のウェイポイントに関連付けるためのHTTPの拡張機能が提案されていますが、これらの拡張機能は広く実装されていません。
- HTTP の認証メカニズムの詳細については、第 12 章を参照してください。

## 6.8 Proxy Interoperation
- クライアント、サーバー、プロキシは、複数のベンダーによって、異なるバージョンのHTTP仕様で構築されています。また、様々な機能をサポートし、様々なバグを持っています。プロキシサーバは、クライアント側とサーバ側の機器の間を取り持つ必要がありますが、これらの機器は異なるプロトコルを実装していたり、面倒な癖があったりします。

### 6.8.1 Handling Unsupported Headers and Methods
- プロキシサーバは、プロキシサーバを通過するすべてのヘッダフィールドを理解しているわけではありません。いくつかのヘッダーはプロキシ自身よりも新しいかもしれないし、 他のヘッダーは特定のアプリケーションに固有のカスタマイズされたヘッダーフィールドかもしれない。プロキシは認識できないヘッダーフィールドを転送(forward)しなければならず、同じ名前のヘッダーフィールドの相対的な順番を維持しなければ ならない[17]。同様に、プロキシがあるメソッドを知らない場合、プロキシは可能であればメッセージを次のホップに転送(forward)することを 試みるべきである。
- [17] 同じフィールド名を持つ複数のメッセージヘッダーフィールドがメッ セージ中に存在するかもしれないが、それらが存在する場合、それらは等価にカンマ区切りのリストに結合できなければならない。同じフィールド名を持つヘッダーフィールドを受け取る順番は、そ れゆえに結合されたフィールド値の解釈にとって重要である。そのためプロキシはメッセージを転送(forward)するときにこれらの同じ名 称のフィールド値の相対的な順番を変更できない。
- Microsoft Outlookを介したHotmailへのアクセスでは、HTTP拡張メソッドが多用されているため、サポートされていないメソッドをトンネリングできないプロキシは、今日のほとんどのネットワークでは実行できないかもしれません。

### 6.8.2 OPTIONS: Discovering Optional Feature Support
- HTTP OPTIONS メソッドは、クライアント（またはプロキシ）に、ウェブサーバのサポートされている機能（サポートされているメソッドなど）や、ウェブサーバ上の特定のリソースを発見させます（図6-26）。クライアントはOPTIONSを使ってサーバの機能を事前に確認できるため、機能レベルの異なるプロキシやサーバとの相互運用が容易になります。
- OPTIONSリクエストのURIにアスタリスク(*)が付いている場合、そのリクエストはサーバーがサポートする機能全体に関わるものです。
- 成功すると、OPTIONS メソッドは、サーバーでサポートされている、またはリソースで利用可能なオプション機能を記述するさまざまなヘッダーフィールドを含む 200 OK 応答を返します。HTTP/1.1 が応答で指定する唯一のヘッダーフィールドは Allow ヘッダーであり、これはサーバー（またはサーバー上の特定のリソース）がどのようなメソッドをサポートしているかを記述している。[18] OPTIONS はより多くの情報を含むオプションの応答ボディを許可しているが、これは未定義である。

### 6.8.3 The Allow Header
- Allow entityヘッダーフィールドは、リクエストURIで特定されるリソース、またはリクエストURIが*の場合はサーバー全体でサポートされるメソッドのセットを列挙します。
- Allowヘッダーは、新しいリソースでサポートされるべきメソッドを推奨するために、リクエストヘッダーとして使用することができます。サーバーはこれらのメソッドをサポートする必要はなく、実際にサポートされているメソッドを列挙したAllowヘッダーをマッチング レスポンスに含めるべきである。
- プロキシは、たとえ指定されたすべてのメソッドを理解していなくても、 Allowヘッダーフィールドを修正することはできない。なぜなら、クライア ントはオリジンサーバーと話すための他のパスを持っているかもしれないから である。

# Chapter7. Caching
- Webキャッシュは、頻繁にアクセスがあるドキュメントのコピーを自動的に保持するHTTPデバイスです。Webリクエストがキャッシュに到達したとき、ローカルに「キャッシュ」されたコピーがあれば、オリジンサーバーからではなく、ローカルストレージからドキュメントが提供されます。キャッシュには次のような利点があります。
  - キャッシュは冗長なデータ転送を減らし、ネットワーク料金を節約できる。
  - キャッシュはネットワークのボトルネックを解消します。帯域幅を増やさなくてもページの読み込みが速くなります。
  - キャッシュはオリジンサーバーへの要求を軽減します。サーバーの応答が速くなり、過負荷を回避できます。
  - キャッシュは、距離による遅延を軽減します。（ページが遠くにあると読み込みが遅くなるため。）
- この章では、キャッシュがどのようにしてパフォーマンスを向上させ、コストを削減するのか、その効果をどのように測定するのか、そしてキャッシュの効果を最大化するためにはどこに配置すればよいのかを説明します。また、HTTPがキャッシュのコピーを新鮮に保つ方法や、キャッシュが他のキャッシュやサーバーとどのように相互作用するかについても説明します。

## 7.1 Redundant Data Transfers - 冗長なデータ転送
- 複数のクライアントが人気のあるオリジンサーバーのページにアクセスすると、サーバーは同じドキュメントを複数回、各クライアントに送信します。同じデータが何度もネットワーク上を行き来することになるのです。このような冗長なデータ転送は、高価なネットワーク帯域を消費し、転送速度を低下させ、ウェブサーバーに負荷をかけます。キャッシュでは、サーバーからの最初のレスポンスのコピーを保持します。後続のリクエストは、キャッシュされたコピーから実行することができ、オリジンサーバーとの間の無駄な重複したトラフィックを削減します。

## 7.2 Bandwidth Bottlenecks
- また、キャッシュはネットワークのボトルネックを解消します。多くのネットワークでは、リモートサーバーよりもローカルネットワークのクライアントに多くの帯域を提供しています（図7-1）。クライアントは、途中にある最も遅いネットワークの速度でサーバーにアクセスします。クライアントが高速なLAN上のキャッシュからコピーを取得する場合、キャッシュはパフォーマンスを向上させることができます（特に大きなドキュメントの場合）。

## 7.3 Flash Crowds
- キャッシングは、フラッシュクラウドを解消するために特に重要です。フラッシュ・クラウドとは、ニュース速報、電子メールの大量送信、有名人のイベントなどの突発的な出来事により、多くの人がほぼ同時にウェブ・ドキュメントにアクセスすることをいいます（図7-2）。その結果、冗長なトラフィックが急増し、ネットワークやWebサーバが壊滅的な状態に陥ることがあります。

## 7.4 Distance Delays
- 帯域が問題にならなくても、距離が問題になることがあります。すべてのネットワークルーターは、インターネットトラフィックに遅延をもたらします。また、クライアントとサーバーの間にそれほど多くのルーターがなくても、光の速さだけでかなりの遅延が発生します。
- 近くのマシンルームにキャッシュを配置することで、ドキュメントの移動距離を数千マイルから数十ヤードにまで縮めることができます。

## 7.5 Hits and Misses
- だから、キャッシュは役に立つ。しかし、キャッシュは世界中のすべてのドキュメントのコピーを保存するものではありません[3]。
- キャッシュに届いたリクエストの中には、利用可能なコピーを提供できる場合があります。これをキャッシュヒットと呼ぶ（図7-4a）。他のリクエストはキャッシュに到着しても、利用可能なコピーがないためにオリジン・サーバーに転送されるだけです。これはキャッシュミスと呼ばれる（図7-4b）。

### 7.5.1 Revalidations
- オリジンサーバーのコンテンツは変更される可能性があるため、キャッシュは時々、自分のコピーがサーバーとの間で最新の状態であるかどうかをチェックする必要があります。このような「新鮮さのチェック」をHTTPの再検証（revalidations）と呼びます（図7-4c）。再検証を効率的に行うために、HTTP は、サーバーからオブジェクト全体を取得することなく、コンテンツがまだ新鮮であるかどうかを迅速に確認できる特別なリクエストを定義しています。
- キャッシュは、いつでも好きなときに好きなだけコピーを再検証することができます。しかし、キャッシュには何百万ものドキュメントが含まれていることが多く、また、ネットワークの帯域幅も限られているため、ほとんどのキャッシュでは、クライアントからの要求があり、コピーが十分に古くなってから、コピーの再検証を行っています。新鮮さをチェックするための HTTP ルールについては、この章の後半で説明します。
- キャッシュがキャッシュされたコピーを再検証する必要があるときは、オリジンサーバーに小さな再検証リクエストを送ります。コンテンツが変更されていなければ、サーバーは小さな 304 Not Modified 応答を返します。キャッシュはコピーがまだ有効であることを知るとすぐに、コピーを一時的に新鮮であるとマークし、そのコピーをクライアントに提供します（図7-5a）。これを再検証ヒットまたはスローヒットと呼びます。オリジンサーバーに確認する必要があるため、純粋なキャッシュヒットよりは遅くなりますが、サーバーからオブジェクトデータを取得しないため、キャッシュミスよりは速くなります。
- HTTP には、キャッシュされたオブジェクトを再検証するためのツールがいくつかありますが、最も一般的なのは If-Modified-Since ヘッダです。GETリクエストに追加されたこのヘッダは、コピーがキャッシュされた時点以降にオブジェクトが変更された場合にのみ、そのオブジェクトを送信するようにサーバに指示します。
- ここでは、サーバーのコンテンツが変更されていない場合、サーバーのコンテンツが変更されている場合、サーバーが削除されている場合、の3つの状況で、GET If-Modified-Sinceリクエストがサーバーに到着した場合にどうなるかを説明します。

  - Revalidate hit
    - サーバーオブジェクトが変更されていない場合、サーバーはクライアントに小さな HTTP 304 Not Modified レスポンスを送信する。これを図7-6に示す。
  - Revalidate miss
    - サーバーオブジェクトが変更されている（キャッシュされたコピーと異なる）場合、サーバーはクライアントに対して、完全なコンテンツを含む通常のHTTP 200 OKレスポンスを送信します。
  - Object deleted
    - サーバーオブジェクトが削除されている場合、サーバーは404 Not Foundレスポンスを返送し、キャッシュはそのコピーを削除します。

### 7.5.2 Hit Rate
- キャッシュから処理されたリクエストの割合は、キャッシュヒット率（またはキャッシュヒットレシオ）[4]、またはドキュメントヒット率（またはドキュメントヒットレシオ）と呼ばれることもあります。ヒット率の範囲は 0 から 1 ですが、しばしばパーセンテージで表現され、0% はすべてのリクエストがミス（ネットワーク上でドキュメントを取得しなければならなかった）であり、100% はすべてのリクエストがヒット（キャッシュ内にコピーがあった）であることを意味します[5]。
  - [5] 再検証ヒットをヒット率に含めることもありますが、ヒット率と再検証ヒット率を別々に測定することもあります。ヒット率を調べる際には、何をもって「ヒット」とするかを確認してください。
- キャッシュ管理者は、キャッシュのヒット率を100%に近づけたいと考えています。実際に得られるヒット率は、キャッシュの大きさ、キャッシュユーザーの関心事がどれだけ似ているか、キャッシュデータの変更やパーソナライズの頻度、キャッシュの構成などによって異なります。ヒット率を予測するのは難しいのですが、今日のささやかなウェブキャッシュでは40％のヒット率が妥当なところでしょう。キャッシュの良いところは、控えめなサイズのキャッシュであっても、パフォーマンスを大幅に向上させ、トラフィックを削減するのに十分な人気のあるドキュメントが含まれている場合があることです。キャッシュは、有用なコンテンツがキャッシュに残るように努力します。

### 7.5.3 Byte Hit Rate
- ドキュメントのヒット率がすべてを物語るわけではありません。なぜなら、ドキュメントはすべて同じサイズではないからです。大きなオブジェクトは、そのサイズのために、アクセス頻度は低くても、データトラフィック全体への貢献度は高い場合があります。このような理由から、バイトヒット率という指標を好む人もいます（特に、1バイトごとのトラフィックに課金される人は要注意！）。
- バイトヒット率とは、転送された全バイトのうち、キャッシュから提供されたバイトの割合を表します。この指標は、トラフィック削減の度合いを表しています。バイトヒット率が100％の場合、すべてのバイトがキャッシュから提供され、インターネット上にトラフィックが流れないことを意味します。
- ドキュメント・ヒット・レートとバイト・ヒット・レートは、どちらもキャッシュのパフォーマンスを測るのに有効です。ドキュメントヒット率は、どれだけ多くのウェブトランザクションが送信ネットワークから遮断されたかを表します。トランザクションには固定された時間があり、その時間はしばしば大きくなります（例えば、サーバーへのTCP接続の設定など）。
- ドキュメントヒット率を向上させることで、全体的なレイテンシー（遅延）の削減が最適化されます。バイト・ヒット・レートは、インターネットからどれだけ多くのバイトが削除されたかを示します。バイトヒット率を向上させることで、帯域幅の節約が最適化されます。

### 7.5.4 Distinguishing Hits and Misses
- 残念ながら、HTTPではクライアントがレスポンスがキャッシュヒットなのかオリジンサーバーからのアクセスなのかを判別する方法がありません。どちらの場合も、レスポンスコードは200 OKで、レスポンスにボディがあることを示します。商用のプロキシキャッシュの中には、キャッシュで何が起こったかを説明するために、Viaヘッダーに追加情報を付けるものもあります。
- 通常、クライアントが応答がキャッシュから来たかどうかを検知する方法の一つは、Dateヘッダを使用することです。応答中のDateヘッダの値を現在の時刻と比較することで、クライアントは多くの場合、その古い日付の値によってキャッシュされた応答を検出することができる。また、クライアントがキャッシュされた応答を検知する別の方法として、応答の古さを示すAgeヘッダーがあります（「Age」を参照）。

## 7.6 Cache Topologies
- キャッシュには、1人のユーザー専用のものと、数千人のユーザーで共有するものがあります。専用キャッシュは、プライベートキャッシュと呼ばれます。プライベート・キャッシュは個人用のキャッシュであり、1人のユーザーに人気のあるページが含まれる（図7-7a）。共有キャッシュはパブリックキャッシュと呼ばれます。パブリック・キャッシュには、ユーザー・コミュニティで人気のあるページが含まれています（図7-7b）。

### 7.6.1 Private Caches
- プライベート・キャッシュは馬力や記憶容量をあまり必要としないため、小型で安価に作ることができます。ウェブブラウザには、プライベートキャッシュが組み込まれています。ほとんどのブラウザは、人気のあるドキュメントをパソコンのディスクやメモリにキャッシュし、キャッシュのサイズや設定を変更することができます。また、ブラウザのキャッシュの中を覗いて、何が入っているかを確認することもできます。

### 7.6.2 Public Proxy Caches
- パブリックキャッシュは、キャッシングプロキシサーバー、あるいはより一般的にはプロキシキャッシュと呼ばれる、特別な共有プロキシサーバーです（プロキシについては第6章で説明しました）。プロキシキャッシュは、ローカルキャッシュからドキュメントを提供したり、ユーザーに代わってサーバーに問い合わせたりします。パブリックキャッシュは複数のユーザーからのアクセスを受けるため、冗長なトラフィックを排除する機会が多い[6]。
  - [6] パブリック・キャッシュはユーザ・コミュニティの多様な関心事をキャッシュするので、個々のユーザの関心事に振り回されることなく、人気のあるドキュメントのセットを保持するのに十分な大きさが必要である。
- 図7-8aでは、各クライアントが新しい「ホット」なドキュメント(まだプライベート・キャッシュに入っていない)に冗長にアクセスしています。各プライベート・キャッシュは同じドキュメントをフェッチし、ネットワークを何度も横断する。図7-8bのように、共有されたパブリック・キャッシュでは、キャッシュは人気のあるオブジェクトを一度だけフェッチする必要があり、共有コピーを使用してすべてのリクエストを処理するため、ネットワーク・トラフィックが減少する。
- プロキシ・キャッシュは、第6章で説明したプロキシのルールに従います。プロキシキャッシュを使用するようにブラウザを設定するには、手動でプロキシを指定するか、プロキシの自動設定ファイルを設定します（6.4.1項参照）。また、インターセプトプロキシを使用すると、ブラウザを設定せずに、キャッシュを介してHTTPリクエストを強制的に実行することができます（第20章参照）。

### 7.6.3 Proxy Cache Hierarchies
- 実際には、多くの場合、キャッシュの階層を展開することが理にかなっています。小さなキャッシュでのキャッシュミスは、残りの「蒸留」トラフィックを処理するより大きな親キャッシュに流されます。図7-9は、2階層のキャッシュ階層を示しています[7]。このアイデアは、クライアントの近くに小さくて安価なキャッシュを使用し、多くのユーザーが共有するドキュメントを保持するために、上位の階層にはより強力なキャッシュを使用するというものです[8]。
  - [7] クライアントがブラウザキャッシュを持つブラウザの場合、図7-9は技術的には3階層のキャッシュ階層を示しています。
  - [8] 親キャッシュは、より多くのユーザに人気のあるドキュメントを保持するために、より大きく、より高性能である必要があるかもしれません。なぜなら、親キャッシュは、関心事が多様である可能性のある多くの子のトラフィックを集約して受け取るからです。
- うまくいけば、ほとんどのユーザは近くのレベル1キャッシュでキャッシュ・ヒットを得ることができます（図7-9aに示すように）。そうでない場合は、より大きな親キャッシュでリクエストを処理できるかもしれません(図7-9b)。深いキャッシュ階層では、キャッシュの長いチェーンを経由することが可能ですが、介在する各プロキシは、プロキシのチェーンが長くなると顕著になる、いくつかのパフォーマンスペナルティを課します[9]。
  - [9] 実際には、ネットワークアーキテクトは、連続するプロキシを2つまたは3つに制限しようとする。しかし、新世代の高性能プロキシサーバが登場すれば、プロキシチェーンの長さが問題にならなくなるかもしれない。

### 7.6.4 Cache Meshes, Content Routing, and Peering
- ネットワークアーキテクトの中には、単純なキャッシュ階層ではなく、複雑なキャッシュメッシュを構築する人もいる。
キャッシュメッシュ内のプロキシキャッシュは、より洗練された方法で相互に通信し、どの親キャッシュと通信するか、あるいはキャッシュを完全にバイパスしてオリジンサーバに直接接続するかなど、動的なキャッシュ通信の決定を行います。このようなプロキシキャッシュは、コンテンツへのアクセス、管理、および配信の方法についてルーティングの決定を行うため、コンテンツルータと表現することができます。
- キャッシュメッシュ内のコンテンツルーティングのために設計されたキャッシュは、以下のすべてを行うことができます（中略）。
  - URL に基づいて、親キャッシュまたはオリジンサーバを動的に選択する。
  - URLに基づいて、親キャッシュを動的に選択する。
  - 親キャッシュにアクセスする前に、ローカルエリアのキャッシュを検索してキャッシュされたコピーを探す。
  - 他のキャッシュに、自らにキャッシュされたコンテンツの一部へのアクセスを許可するが、自らのキャッシュを経由したインターネットの通過は許可しない。
- このようなキャッシュ間のより複雑な関係により、異なる組織が相互にピアリングを行い、相互利益のためにキャッシュを接続することができます。選択的なピアリングサポートを提供するキャッシュは、兄弟キャッシュと呼ばれます（図7-10）。HTTPは兄弟キャッシュをサポートしていないため、インターネット・キャッシュ・プロトコル(ICP)やハイパーテキスト・キャッシュ・プロトコル(HTCP)などのプロトコルでHTTPを拡張しています。これらのプロトコルについては、第20章で説明します。

## 7.7 Cache Processing Steps
- 最近の商用プロキシキャッシュは非常に複雑です。非常に高性能で、HTTPやその他の技術の高度な機能をサポートするように作られています。しかし、微妙な違いはあっても、ウェブキャッシュの基本的な動作はほとんど単純です。HTTP GET メッセージの基本的なキャッシュ処理シーケンスは、7 つのステップで構成されています（図 7-11 に図示）。

1. 受信-キャッシュはネットワークから到着したリクエストメッセージを読み込みます。
2. 解析-キャッシュはメッセージを解析し、URL とヘッダを抽出します。
3. ルックアップ-キャッシュは、ローカルコピーが利用可能かどうかをチェックし、利用可能でない場合はコピーをフェッチします（そしてローカルに保存します）。
4. 新鮮さチェック-キャッシュされたコピーが十分に新鮮であるかどうかをチェックし、新鮮でない場合はサーバーに更新を要求します。
5. レスポンスの作成-キャッシュは、新しいヘッダとキャッシュされた本文を含むレスポンスメッセージを作成します。
6. 送信-キャッシュはネットワーク経由でクライアントにレスポンスを送信します。
7. ロギング-オプションとして、キャッシュはトランザクションを説明するログファイルエントリを作成します。

### 7.7.1 Step 1: Receiving
- ステップ1では、キャッシュがネットワーク接続のアクティビティを検出し、受信データを読み取る。高性能なキャッシュは、複数の受信接続から同時にデータを読み取り、メッセージ全体が到着する前にトランザクションの処理を開始します。

### 7.7.2 Step 2: Parsing
- 次に、キャッシュはリクエストメッセージを断片的に解析し、ヘッダ部分を操作しやすいデータ構造に配置します。これにより、キャッシュソフトウェアがヘッダーフィールドを処理したり、いじったりすることが容易になります[10]。

### 7.7.3 Step 3: Lookup
- ステップ3では、キャッシュがURLを受け取り、ローカルコピーをチェックします。ローカルコピーは、メモリに保存されている場合もあれば、ローカルディスクに保存されている場合もありますし、近くの別のコンピュータに保存されている場合もあります。プロ仕様のキャッシュでは、高速なアルゴリズムを使用して、オブジェクトがローカルキャッシュで利用可能かどうかを判断します。ドキュメントがローカルで利用できない場合は、状況や設定に応じて、オリジンサーバーや親プロキシから取得したり、失敗を返したりします。
- キャッシュされたオブジェクトには、サーバーのレスポンスボディとオリジナルのサーバーレスポンスヘッダーが含まれているため、キャッシュヒット時に正しいサーバーヘッダーを返すことができます。また、キャッシュされたオブジェクトにはメタデータが含まれており、オブジェクトがキャッシュに置かれていた期間や使用回数などを記録するために使用されます[11]。

### 7.7.4 Step 4: Freshness Check
- HTTPでは、キャッシュにサーバーのドキュメントのコピーを一定期間保持させることができます。この期間中、ドキュメントは「新鮮」とみなされ、キャッシュはサーバーに問い合わせることなくドキュメントを提供することができます。しかし、キャッシュされたコピーが長時間放置され、ドキュメントの新鮮さの限界を超えると、オブジェクトは「陳腐化」したとみなされ、キャッシュはサーバーとの再検証を行い、ドキュメントの変更をチェックしてから提供する必要があります。さらに事を複雑にしているのは、クライアントがキャッシュに送信するリクエストヘッダであり、これはキャッシュに対して再検証の試行、または完全な検証回避を強制したりすることができます。
- HTTP には鮮度チェックのための非常に複雑なルールがありますが、これはキャッシュ製品がサポートする多数の設定オプションや、HTTP 以外の鮮度標準との相互運用の必要性によって悪化しています。この章の残りの部分のほとんどを、鮮度計算の説明に充てることにします。

### 7.7.5 Step 5: Response Creation
- キャッシュされたレスポンスはオリジンサーバーから来たように見せたいので、キャッシュは、キャッシュされたサーバーのレスポンスヘッダーをレスポンスヘッダーの出発点として使用します。これらのベースとなるヘッダーは、キャッシュによって修正され、補強されます。
- キャッシュは、クライアントに合わせてヘッダを適応させる役割を果たします。例えば、クライアントが HTTP/1.1 レスポンスを期待しているのに、サーバが HTTP/1.0 レスポンス (あるいは HTTP/0.9 レスポンス) を返すことがあります。この場合、キャッシュはそれに合わせてヘッダを変換する必要があります。キャッシュはまた、キャッシュの鮮度情報 (Cache-Control、Age、Expires ヘッダ) を挿入し、多くの場合、プロキシキャッシュがリクエストを処理したことを示す Via ヘッダを含めます。
- キャッシュは Date ヘッダーを調整してはいけないことに注意してください。Date ヘッダーは、オブジェクトがオリジンサーバーで最初に生成されたときの日付を表します。

### 7.7.6 Step 6: Sending
- レスポンスヘッダーの準備ができると、キャッシュはレスポンスをクライアントに送り返します。他のプロキシサーバと同様に、プロキシキャッシュはクライアントとの接続を管理する必要がある。高性能のキャッシュは、データを効率的に送信するために懸命に働き、しばしばローカルストレージとネットワークI/Oバッファ間でのドキュメントコンテンツのコピーを回避します。

### 7.7.7 Step 7: Logging
- ほとんどのキャッシュは、キャッシュの使用状況に関するログファイルと統計情報を保持します。各キャッシュトランザクションが完了すると、キャッシュはキャッシュのヒット数とミス数 (およびその他の関連メトリクス) をカウントする統計情報を更新し、リクエストタイプ、URL、および何が起こったかを示すエントリをログファイルに挿入します。
- 最も一般的なキャッシュログフォーマットは、SquidログフォーマットとNetscape拡張コモンログフォーマットですが、多くのキャッシュ製品では、カスタムログファイルを作成することができます。ログファイルのフォーマットについては、第21章で詳しく説明します。

### 7.7.8 Cache Processing Flowchart
- 図 7-12 は、キャッシュが URL を GET するリクエストをどのように処理するかを簡略化して示したものである[12]。
- [12] 図 7-12 で説明したリソースの再検証とフェッチは、条件付きリクエストで一度に行うことができる（セクション 7.8.4 参照）。

## 7.8 Keeping Copies Fresh
- キャッシュされたコピーは、サーバー上のドキュメントとすべてが一致するとは限りません。キャッシュは、常に古いデータを提供していては意味がありません。キャッシュされたデータは、サーバーのデータとの一貫性を保つ必要があります。
- HTTP には、どのキャッシュにドキュメントのコピーがあるかをサーバーが覚えていなくても、キャッシュデータとサーバーとの一貫性を十分に保つための簡単なメカニズムがあります。HTTP はこれらの単純な仕組みを、ドキュメントの失効とサーバーの再検証と呼んでいます。

### 7.8.1 Document Expiration

### 7.8.2 Expiration Dates and Ages

### 7.8.3 Server Revalidation

### 7.8.4 Revalidation with Conditional Methods

### 7.8.5 If-Modified-Since: Date Revalidation

### 7.8.6 If-None-Match: Entity Tag Revalidation

### 7.8.7 Weak and Strong Validators

### 7.8.8 When to Use Entity Tags and Last-Modified Dates

## 7.9 Controlling Cachability
- HTTPでは、サーバーがドキュメントの有効期限が切れるまでのキャッシュ期間を指定する方法がいくつか定義されています。優先度の高い順に、サーバーは以下の方法を取ることができます。
  - レスポンスに Cache-Control: no-store ヘッダを付加する。
  - Cache-Control: must-revalidate ヘッダを応答に添付する。
  - レスポンスに Cache-Control: no-cache ヘッダーを付ける。
  - レスポンスに Cache-Control: max-age ヘッダーを付けます。
  - レスポンスに Expires date ヘッダーを付けます。
  - 有効期限情報を添付せず、キャッシュに自身の発見的な有効期限を決定させます。
- このセクションでは、キャッシュ制御ヘッダーについて説明します。次の 7.10 節では、コンテンツごとに異なるキャッシュ情報を割り当てる方法について説明します。

### 7.9.1 No-Cache and No-Store Headers
- HTTP/1.1 には、キャッシュされないオブジェクトをマークする方法がいくつかあります。技術的には、これらのキャッシュ不可能なページは、決してキャッシュに保存されるべきではなく、したがって、新鮮さを計算する段階に達することはありません。ここでは、ドキュメントをキャッシュ不能にするHTTPヘッダをいくつか紹介します。

```
Pragma: no-cache
Cache-Control: no-cache
Cache-Control: no-store
```

- RFC 2616 では、キャッシュが「no-cache」とマークされたレスポンスを保存することを許可していますが、キャッシュはレスポンスを提供する前にオリジンサーバーでレスポンスを再検証する必要があります。no-store "とマークされた応答は、キャッシュがその応答のコピーを作成することを禁止します。キャッシュはこのレスポンスを保存してはいけません。
- Pragma: no-cache ヘッダーは、HTTP 1.0+ との下位互換性のために HTTP 1.1 に含まれています。技術的には HTTP リクエストに対してのみ有効で定義されていますが、HTTP 1.0 と 1.1 の両方のリクエストおよびレスポンスの拡張ヘッダとして広く使用されています。HTTP 1.1 アプリケーションは、CacheControl: no-cache を使用する必要があります。ただし、Pragma: no-cache しか理解できない HTTP 1.0 アプリケーションを扱う場合は例外です。

### 7.9.2 Max-Age Response Headers
- Cache-Control: max-age ヘッダーは、ドキュメントがサーバーから送られてきてから何秒経ったら新鮮だと判断できるかを示します。また、s-maxageヘッダー（"maxage "にハイフンがないことに注意）もあります。これはmax-ageと同じように動作しますが、共有（パブリック）キャッシュにのみ適用されます。

```
Cache-Control: max-age=3600
Cache-Control: s-maxage=3600
```

- サーバーは、最大経過時間をゼロに設定することで、ドキュメントをキャッシュしないか、またはアクセスごとにリフレッシュするようキャッシュに要求できます。

```
Cache-Control: max-age=0
Cache-Control: s-maxage=0
```

### 7.9.3 Expires Response Headers
- 非推奨の Expires ヘッダーは、秒単位の時間ではなく、実際の有効期限を指定します。後にHTTPの設計者は、多くのサーバの時計は同期していないか不正確であるため、期限切れを絶対時間ではなく経過秒数で表現する方が良いと判断しました。同様の新鮮さの寿命は、expires値とdate値の差の秒数を計算することで算出できます。

```
Expires: Fri, 05 Jul 2002, 05:00:00 GMT
```

- サーバによっては、Expires: 0 応答ヘッダを送り返して、ドキュメントが常に期限切れになるようにしようとするものもありますが、この構文は違法であり、一部のソフトウェアで問題が発生する可能性があります。この構文を入力としてサポートするようにすべきですが、生成すべきではありません。

### 7.9.4 Must-Revalidate Response Headers
- Cache-Control: must-revalidate レスポンスヘッダーは、新鮮さの計算メカニズムをバイパスし、アクセスごとに再検証するようキャッシュに指示します。

```
Cache-Control: must-revalidate
```

- レスポンスにこのヘッダを付けることは、実際には Cache-Control: no-cache を使うよりも強力なキャッシュ制限となります。というのも、このヘッダはキャッシュに対して、キャッシュされたコピーを提供する前に必ずレスポンスを再検証するように指示するからです。これは、サーバが利用できない場合でも同様です。その場合、キャッシュはレスポンスを再検証できないので、キャッシュされたコピーを提供すべきではありません。no-store" 指示だけがキャッシュの動作をより制限します。 no-store 指示はキャッシュにリソースのコピーを作成しないように指示するからです (それによって、キャッシュは常にリソースを取得することになります)。

### 7.9.5 Heuristic Expiration
- 応答が Cache-Control: max-age ヘッダーも Expires ヘッダーも含んでいない場合、キャッシュはヒューリスティックな最大ageを計算してもよい。どのようなアルゴリズムを使ってもよいが、結果として最大年齢が24時間を超える場合には、応答ヘッダにHeuristic Expiration Warning (Warning 13)ヘッダを追加すべきである。私たちの知る限り、この警告情報をユーザーに提供しているブラウザはほとんどありません。
- 一般的なヒューリスティック満了アルゴリズムのひとつである LM-Factor アルゴリズムは、ドキュメントに最終更新日が含まれている場合に使用できる。LM-Factor アルゴリズムでは、last-modified の日付をドキュメントの変化しやすさの推定値として使用する。

### 7.9.6 Client Freshness Constraints

### 7.9.7 Cautions

## 7.10 Setting Cache Controls
- Webサーバによって、HTTPのcache-controlやexpirationヘッダを設定する仕組みが異なります。このセクションでは、人気の高い Apache ウェブサーバがどのようにキャッシュコントロールをサポートしているかについて簡単に説明します。具体的な詳細については、ウェブサーバのマニュアルを参照してください。

### 7.10.1 Controlling HTTP Headers with Apache
- Apache ウェブサーバは、HTTP キャッシュを制御するヘッダを設定するためのいくつかのメカニズムを提供しています。これらのメカニズムの多くは、デフォルトでは有効になっていませんので、それらを有効にする必要があります（場合によっては、最初にApacheの拡張モジュールを入手する必要があります）。ここでは、Apache の機能のいくつかについて簡単に説明します。

- mod_headers
  - mod_headers モジュールは個々のヘッダを設定することができます。このモジュールがロードされると、個々の HTTP ヘッダを設定するためのディレクティブで Apache の設定ファイルを補強することができます。また、これらの設定を Apache の正規表現やフィルタと組み合わせて使うことで、 ヘッダを個々のコンテンツに関連付けることができます。以下は、ディレクトリ内のすべての HTML ファイルを読めないようにする設定の例です。
  ```
  <Files *.html>
   Header set Cache-control no-cache
  </Files>
  ```

- mod_expires
  - mod_expires モジュールは、正しい有効期限を持つ Expires ヘッダを 自動的に生成するプログラムロジックを提供します。このモジュールを使うと、ドキュメントが最後にアクセスされてから、 あるいは最後に修正されてから、ある期間の有効期限を設定することが できます。また、このモジュールでは、ファイルタイプごとに異なる有効期限を設定したり、「access plus 1 month」のような便利な冗長記述を使ってキャッシュ可能性を表現したりすることができます。以下にいくつかの例を示します。

- mod_cern_meta
  - mod_cern_meta モジュールは、HTTP ヘッダのファイルを特定のオブジェクトと関連付けることができます。このモジュールを有効にすると、制御したいドキュメントごとに「メタファイル」のセットを作成し、各メタファイルに必要なヘッダを追加します。

### 7.10.2 Controlling HTML Caching Through HTTP-EQUIV

## 7.11 Detailed Algorithms

## 7.12 Caches and Advertising
